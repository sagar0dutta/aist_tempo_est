{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import compute_tempo as ctempo\n",
    "# from utils.extract_dance_onsets import extract_body_onsets\n",
    "# from rms_extract_dance_onsets import *\n",
    "\n",
    "\n",
    "# from aist_pos1s_EsTempo import *\n",
    "marker_dict={    \n",
    "0: \"nose\", 1: \"left_eye\", 2: \"right_eye\", 3: \"left_ear\",4: \"right_ear\",5: \"left_shoulder\",\n",
    "6: \"right_shoulder\",7: \"left_elbow\",8: \"right_elbow\",9: \"left_wrist\",10: \"right_wrist\",\n",
    "11: \"left_hip\",12: \"right_hip\",13: \"left_knee\",14: \"right_knee\",15: \"left_ankle\",16: \"right_ankle\",}  \n",
    "\n",
    "def load_pickle(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        json_data = pickle.load(f)\n",
    "    return json_data\n",
    "\n",
    "def save_to_pickle(filepath, data):\n",
    "    # filepath = os.path.join(savepath, filename)\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "def create_onset_dir(tempo_dir):\n",
    "    # main_dir = \"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result\"\n",
    "    directories = [f\"{tempo_dir}/pos\", f\"{tempo_dir}/pos/ax0\",\n",
    "                   f\"{tempo_dir}/pos/ax1\", f\"{tempo_dir}/pos/combination\",\n",
    "                   f\"{tempo_dir}/pos/resultant\",\n",
    "                   \n",
    "                   f\"{tempo_dir}/vel\", f\"{tempo_dir}/vel/ax0\",\n",
    "                   f\"{tempo_dir}/vel/ax1\", f\"{tempo_dir}/vel/combination\",\n",
    "                   f\"{tempo_dir}/vel/resultant\",]\n",
    "    \n",
    "    for dir_path in directories:\n",
    "        # full_path = os.path.join(main_dir, dir_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        \n",
    "# create_onset_dir(\"/itf-fi-ml/home/sagardu/aist_tempo_est/rms_extracted_body_onsets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## March 11 Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onset Extraction Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marker_dict = {9: \"left_wrist\", 10: \"right_wrist\", \n",
    "#                 15: \"left_ankle\", 16: \"right_ankle\", \n",
    "#                 }   # 11: \"left_hip\",12: \"right_hip\"\n",
    "\n",
    "config1 = {\"sub_dir\": [\"hand\"], \"mode\": [\"zero_uni\", \"zero_bi\"], \n",
    "           \"markerA_id\": [9, 10], \"a\": 60, \"b\": 140, \"metric\": [\"pos\", \"vel\"]}\n",
    "config2 = {\"sub_dir\": [\"foot\"], \"mode\": [\"zero_uni\", \"zero_bi\"],\n",
    "           \"markerA_id\": [15, 16], \"a\": 60, \"b\": 140, \"metric\": [\"pos\", \"vel\"]}\n",
    "\n",
    "configs = [config1, config2]\n",
    "# create_onset_dir(\"/itf-fi-ml/home/sagardu/aist_tempo_est/extracted_body_onsets\", \"thres_0.4\")\n",
    "for cfg in configs:\n",
    "    a = cfg[\"a\"]\n",
    "    b = cfg[\"b\"]\n",
    "    \n",
    "    for sub_dir in cfg[\"sub_dir\"]:\n",
    "        for mode in cfg[\"mode\"]:\n",
    "            for markerA_id in cfg[\"markerA_id\"]:\n",
    "                for metric in cfg[\"metric\"]:\n",
    "                    \n",
    "                    savepath = f\"./extracted_body_onsets_sept25/{metric}\"           \n",
    "                    extract_body_onsets(mode, markerA_id, savepath, h_thres = 0.1,\n",
    "                               vel_mode= \"on\" if metric == \"vel\" else \"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fps = 60\n",
    "# a = 70; b =140\n",
    "\n",
    "# metric = \"pos\"\n",
    "# mode = \"zero_uni\"\n",
    "\n",
    "\n",
    "# onset_dir = f\"./extracted_body_onsets/{metric}\"\n",
    "# save_dir = f\"./extracted_body_onsets/{metric}/combination\"\n",
    "# f_path = \"./aist_dataset/aist_annotation/keypoints2d\"\n",
    "# aist_filelist = os.listdir(f_path)\n",
    "\n",
    "\n",
    "# for idx, filename in enumerate(tqdm(aist_filelist)):\n",
    "\n",
    "    \n",
    "#     test_path = os.path.join(onset_dir, \"ax0\", f\"left_wrist_{mode}_{filename}\")\n",
    "#     isExist = os.path.exists(test_path) \n",
    "#     if not isExist:\n",
    "#         continue\n",
    "                            \n",
    "#     left_hand_x  = load_pickle(os.path.join(onset_dir, \"ax0\", f\"left_wrist_{mode}_{filename}\"))\n",
    "#     left_hand_y  = load_pickle(os.path.join(onset_dir, \"ax1\", f\"left_wrist_{mode}_{filename}\"))\n",
    "    \n",
    "#     right_hand_x = load_pickle(os.path.join(onset_dir, \"ax0\", f\"right_wrist_{mode}_{filename}\"))\n",
    "#     right_hand_y = load_pickle(os.path.join(onset_dir, \"ax1\", f\"right_wrist_{mode}_{filename}\"))\n",
    "    \n",
    "#     left_foot_x  = load_pickle(os.path.join(onset_dir, \"ax0\", f\"left_ankle_{mode}_{filename}\"))\n",
    "#     left_foot_y  = load_pickle(os.path.join(onset_dir, \"ax1\", f\"left_ankle_{mode}_{filename}\"))\n",
    "    \n",
    "#     right_foot_x = load_pickle(os.path.join(onset_dir, \"ax0\", f\"right_ankle_{mode}_{filename}\"))\n",
    "#     right_foot_y = load_pickle(os.path.join(onset_dir, \"ax1\", f\"right_ankle_{mode}_{filename}\"))\n",
    "    \n",
    "#     novelty_length = left_hand_x['raw_signal'].shape[0]\n",
    "    \n",
    "#     key = 'sensor_onsets'\n",
    "#     thres = 0.25\n",
    "    \n",
    "#     bothhand_x = filter_dir_onsets_by_threshold((left_hand_x[key] + right_hand_x[key]), threshold_s= thres, fps=fps)\n",
    "#     bothhand_y = filter_dir_onsets_by_threshold((left_hand_y[key] + right_hand_y[key]), threshold_s= thres, fps=fps)\n",
    "\n",
    "#     bothfoot_x = filter_dir_onsets_by_threshold((left_foot_x[key] + right_foot_x[key]), threshold_s= thres, fps=fps)\n",
    "#     bothfoot_y = filter_dir_onsets_by_threshold((left_foot_y[key] + right_foot_y[key]), threshold_s= thres, fps=fps)\n",
    "    \n",
    "#     lefthand_xy = filter_dir_onsets_by_threshold((left_hand_x[key] + left_hand_y[key]), threshold_s= thres, fps=fps)\n",
    "#     righthand_xy = filter_dir_onsets_by_threshold((right_hand_x[key] + right_hand_y[key]), threshold_s= thres, fps=fps)\n",
    "\n",
    "#     leftfoot_xy = filter_dir_onsets_by_threshold((left_foot_x[key] + left_foot_y[key]), threshold_s= thres, fps=fps)\n",
    "#     rightfoot_xy = filter_dir_onsets_by_threshold((right_foot_x[key] + right_foot_y[key]), threshold_s= thres, fps=fps)\n",
    "    \n",
    "#     # Resultant part\n",
    "#     key1 = 'resultant_onsets'\n",
    "#     left_hand_resultant  = load_pickle(os.path.join(onset_dir, \"resultant\", f\"left_wrist_{mode}_{filename}\"))\n",
    "#     right_hand_resultant  = load_pickle(os.path.join(onset_dir, \"resultant\", f\"right_wrist_{mode}_{filename}\"))\n",
    "\n",
    "#     left_foot_resultant = load_pickle(os.path.join(onset_dir, \"resultant\", f\"left_ankle_{mode}_{filename}\"))\n",
    "#     right_foot_resultant = load_pickle(os.path.join(onset_dir, \"resultant\", f\"right_ankle_{mode}_{filename}\"))\n",
    "    \n",
    "#     both_hand_resultant = filter_dir_onsets_by_threshold((left_hand_resultant[key1] + right_hand_resultant[key1]), threshold_s= thres, fps=fps)\n",
    "#     both_foot_resultant = filter_dir_onsets_by_threshold((left_foot_resultant[key1] + right_foot_resultant[key1]), threshold_s= thres, fps=fps)\n",
    "    \n",
    "    \n",
    "#     json_combi = {\n",
    "#         \"bothhand_x\": bothhand_x,\n",
    "#         \"bothhand_y\": bothhand_y,\n",
    "#         \"lefthand_xy\": lefthand_xy,\n",
    "#         \"righthand_xy\": righthand_xy,\n",
    "#         \"bothfoot_x\": bothfoot_x,\n",
    "#         \"bothfoot_y\": bothfoot_y,\n",
    "#         \"leftfoot_xy\": leftfoot_xy,\n",
    "#         \"rightfoot_xy\": rightfoot_xy,\n",
    "        \n",
    "#         \"both_hand_resultant\": both_hand_resultant,\n",
    "#         \"both_foot_resultant\": both_foot_resultant\n",
    "#     }\n",
    "    \n",
    "    \n",
    "#     sv_fname = f\"{filename}_{mode}_combi_onsets.pkl\"\n",
    "#     fpath2 = os.path.join(save_dir, sv_fname)\n",
    "#     save_to_pickle(fpath2, json_combi)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Tempo - Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = \"music_id_tempo.json\"\n",
    "with open(json_filename, \"r\") as file:\n",
    "    aist_tempo = json.load(file)\n",
    "    \n",
    "def create_dir(main_dir, tempo_dir):\n",
    "    # main_dir = \"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result\"\n",
    "    directories = [f\"{tempo_dir}/pos\",\n",
    "                   f\"{tempo_dir}/vel\", \n",
    "                #    f\"{tempo_dir}/anchor_energy\", \n",
    "                   \n",
    "                #    f\"{tempo_dir}/score\",\n",
    "                #    f\"{tempo_dir}/tempo_data/pos\", \n",
    "                #    f\"{tempo_dir}/tempo_data/vel\",\n",
    "                   ]\n",
    "    \n",
    "    for dir_path in directories:\n",
    "        full_path = os.path.join(main_dir, dir_path)\n",
    "        os.makedirs(full_path, exist_ok=True)\n",
    "        \n",
    "segment_keys = [\"torso_y\",\n",
    "                \"both_hand_x\", \"both_hand_y\", \"both_foot_x\", \"both_foot_y\", \n",
    "                \"lefthand_xy\", \"righthand_xy\", \"leftfoot_xy\", \"rightfoot_xy\", \n",
    "                \"left_hand_x\", \"right_hand_x\", \"left_hand_y\", \"right_hand_y\", \n",
    "                \"left_foot_x\", \"right_foot_x\", \"left_foot_y\", \"right_foot_y\", \n",
    "                \n",
    "                \"bothhand_x_bothfoot_x\", \"bothhand_y_bothfoot_y\",\n",
    "                \"lefthand_xy_righthand_xy\", \"leftfoot_xy_rightfoot_xy\",\n",
    "                \"bothhand_x_bothhand_y\", \"bothfoot_x_bothfoot_y\",\n",
    "                \n",
    "                \"both_hand_resultant\", \"both_foot_resultant\", \"left_hand_resultant\", \n",
    "                \"right_hand_resultant\", \"left_foot_resultant\", \"right_foot_resultant\"]\n",
    "\n",
    "result = { key: {\n",
    "    \"filename\": [],\n",
    "    \"dance_genre\": [],\n",
    "    \"situation\": [],\n",
    "    \"camera_id\": [],\n",
    "    \"dancer_id\": [],\n",
    "    \"music_id\": [],\n",
    "    \"choreo_id\": [],\n",
    "    \"music_tempo\": [],\n",
    "    \"estimated_bpm_per_window\": [],\n",
    "    \"magnitude_per_window\": [],\n",
    "    \"bpm_avg\": [],\n",
    "    \"bpm_mode\": [],\n",
    "    \"bpm_median\": [],\n",
    "} for key in segment_keys }\n",
    "\n",
    "fps = 60\n",
    "w_sec = 5\n",
    "h_sec = w_sec/2\n",
    "window_size = int(fps*w_sec)\n",
    "hop_size = int(fps*h_sec)\n",
    "\n",
    "a = 60 \n",
    "b = 140\n",
    "tempi_range = np.arange(a,b,1)\n",
    "metric = \"pos\"\n",
    "mode = \"zero_bi\"\n",
    "\n",
    "main_dir = \"./saved_result\"\n",
    "create_dir(main_dir, f\"tempo_{a}_{b}\")\n",
    "\n",
    "save_dir = f\"./saved_result/tempo_{a}_{b}/\"\n",
    "onset_dir = f\"./extracted_body_onsets_sept25/{metric}/\"\n",
    "f_path = \"./aist_dataset/aist_annotation/keypoints2d\"\n",
    "aist_filelist = os.listdir(f_path)\n",
    "\n",
    "\n",
    "\n",
    "count= 0\n",
    "for idx, filename in enumerate(tqdm(aist_filelist)):\n",
    "    \n",
    "    file_info = filename.split(\"_\")\n",
    "    dance_genre = file_info[0] \n",
    "    situation = file_info[1] \n",
    "    camera_id = file_info[2] \n",
    "    dancer_id = file_info[3]\n",
    "    music_id = file_info[4]\n",
    "    choreo_id = file_info[5].strip(\".pkl\")\n",
    "    \n",
    "    test_path = os.path.join(onset_dir, \"ax0\", f\"left_wrist_{mode}_{filename}\")\n",
    "    isExist = os.path.exists(test_path) \n",
    "    if not isExist:\n",
    "        continue\n",
    "    \n",
    "    torso_y = load_pickle(os.path.join(\"/itf-fi-ml/home/sagardu/aist_tempo_COM/aist_tempo_est/extracted_body_onsets/pos/ax1\", f\"torso_{mode}_{filename}\"))\n",
    "                            \n",
    "    left_hand_x  = load_pickle(os.path.join(onset_dir, \"ax0\", f\"left_wrist_{mode}_{filename}\"))\n",
    "    left_hand_y  = load_pickle(os.path.join(onset_dir, \"ax1\", f\"left_wrist_{mode}_{filename}\"))\n",
    "    \n",
    "    right_hand_x = load_pickle(os.path.join(onset_dir, \"ax0\", f\"right_wrist_{mode}_{filename}\"))\n",
    "    right_hand_y = load_pickle(os.path.join(onset_dir, \"ax1\", f\"right_wrist_{mode}_{filename}\"))\n",
    "    \n",
    "    left_foot_x  = load_pickle(os.path.join(onset_dir, \"ax0\", f\"left_ankle_{mode}_{filename}\"))\n",
    "    left_foot_y  = load_pickle(os.path.join(onset_dir, \"ax1\", f\"left_ankle_{mode}_{filename}\"))\n",
    "    \n",
    "    right_foot_x = load_pickle(os.path.join(onset_dir, \"ax0\", f\"right_ankle_{mode}_{filename}\"))\n",
    "    right_foot_y = load_pickle(os.path.join(onset_dir, \"ax1\", f\"right_ankle_{mode}_{filename}\"))\n",
    "    \n",
    "    novelty_length = left_hand_x['raw_signal'].shape[0]\n",
    "    \n",
    "    key = 'sensor_onsets'       #   sensor_abs_pos_filtered\n",
    "    thres = 0.2     # time threshold\n",
    "    \n",
    "    bothhand_x = ctempo.filter_dir_onsets_by_threshold((left_hand_x[key] + right_hand_x[key]), threshold_s= thres, fps=fps)\n",
    "    bothhand_y = ctempo.filter_dir_onsets_by_threshold((left_hand_y[key] + right_hand_y[key]), threshold_s= thres, fps=fps)\n",
    "\n",
    "    bothfoot_x = ctempo.filter_dir_onsets_by_threshold((left_foot_x[key] + right_foot_x[key]), threshold_s= thres, fps=fps)\n",
    "    bothfoot_y = ctempo.filter_dir_onsets_by_threshold((left_foot_y[key] + right_foot_y[key]), threshold_s= thres, fps=fps)\n",
    "    \n",
    "    lefthand_xy = ctempo.filter_dir_onsets_by_threshold((left_hand_x[key] + left_hand_y[key]), threshold_s= thres, fps=fps)\n",
    "    righthand_xy = ctempo.filter_dir_onsets_by_threshold((right_hand_x[key] + right_hand_y[key]), threshold_s= thres, fps=fps)\n",
    "\n",
    "    leftfoot_xy = ctempo.filter_dir_onsets_by_threshold((left_foot_x[key] + left_foot_y[key]), threshold_s= thres, fps=fps)\n",
    "    rightfoot_xy = ctempo.filter_dir_onsets_by_threshold((right_foot_x[key] + right_foot_y[key]), threshold_s= thres, fps=fps)\n",
    "    \n",
    "    \n",
    "    ############\n",
    "    # bothhand_x_bothfoot_x = ctempo.filter_dir_onsets_by_threshold((bothhand_x + bothfoot_x), threshold_s= thres, fps=fps)\n",
    "    # bothhand_y_bothfoot_y = ctempo.filter_dir_onsets_by_threshold((bothhand_y + bothfoot_y), threshold_s= thres, fps=fps)\n",
    "    \n",
    "    # lefthand_xy_righthand_xy = ctempo.filter_dir_onsets_by_threshold((lefthand_xy + righthand_xy), threshold_s= thres, fps=fps)\n",
    "    # leftfoot_xy_rightfoot_xy = ctempo.filter_dir_onsets_by_threshold((leftfoot_xy + rightfoot_xy), threshold_s= thres, fps=fps)\n",
    "    \n",
    "    # bothhand_x_bothhand_y = ctempo.filter_dir_onsets_by_threshold((bothhand_x + bothhand_y), threshold_s= thres, fps=fps)\n",
    "    # bothfoot_x_bothfoot_y = ctempo.filter_dir_onsets_by_threshold((bothfoot_x + bothfoot_y), threshold_s= thres, fps=fps)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Resultant part\n",
    "    key1 = 'resultant_onsets'\n",
    "    left_hand_resultant  = load_pickle(os.path.join(onset_dir, \"resultant\", f\"left_wrist_{mode}_{filename}\"))\n",
    "    right_hand_resultant  = load_pickle(os.path.join(onset_dir, \"resultant\", f\"right_wrist_{mode}_{filename}\"))\n",
    "\n",
    "    left_foot_resultant = load_pickle(os.path.join(onset_dir, \"resultant\", f\"left_ankle_{mode}_{filename}\"))\n",
    "    right_foot_resultant = load_pickle(os.path.join(onset_dir, \"resultant\", f\"right_ankle_{mode}_{filename}\"))\n",
    "    \n",
    "    both_hand_resultant = ctempo.filter_dir_onsets_by_threshold((left_hand_resultant[key1] + right_hand_resultant[key1]), threshold_s= thres, fps=fps)\n",
    "    both_foot_resultant = ctempo.filter_dir_onsets_by_threshold((left_foot_resultant[key1] + right_foot_resultant[key1]), threshold_s= thres, fps=fps)\n",
    "    \n",
    "    segment_ax = {\n",
    "        \n",
    "                \"torso_y\": torso_y[key],\n",
    "                \"both_hand_x\": bothhand_x, \"both_hand_y\": bothhand_y, \"both_foot_x\": bothfoot_x, \"both_foot_y\": bothfoot_y,\n",
    "                \"lefthand_xy\": lefthand_xy, \"righthand_xy\": righthand_xy, \"leftfoot_xy\": leftfoot_xy, \"rightfoot_xy\": rightfoot_xy,\n",
    "                \n",
    "                \"left_hand_x\": left_hand_x[key], \"right_hand_x\": right_hand_x[key], \n",
    "                \"left_hand_y\": left_hand_y[key], \"right_hand_y\": right_hand_y[key],\n",
    "                \n",
    "                \"left_foot_x\": left_foot_x[key], \"right_foot_x\": right_foot_x[key],\n",
    "                \"left_foot_y\": left_foot_y[key], \"right_foot_y\": right_foot_y[key],\n",
    "                \n",
    "                # \"bothhand_x_bothfoot_x\": bothhand_x_bothfoot_x, \"bothhand_y_bothfoot_y\": bothhand_y_bothfoot_y,\n",
    "                # \"lefthand_xy_righthand_xy\": lefthand_xy_righthand_xy, \"leftfoot_xy_rightfoot_xy\": leftfoot_xy_rightfoot_xy,\n",
    "                # \"bothhand_x_bothhand_y\": bothhand_x_bothhand_y, \"bothfoot_x_bothfoot_y\": bothfoot_x_bothfoot_y,\n",
    "                \n",
    "                \n",
    "                \"both_hand_resultant\": both_hand_resultant, \"both_foot_resultant\": both_foot_resultant,                         \n",
    "                \"left_hand_resultant\": left_hand_resultant[key1], \"right_hand_resultant\": right_hand_resultant[key1],\n",
    "                \"left_foot_resultant\": left_foot_resultant[key1], \"right_foot_resultant\": right_foot_resultant[key1],\n",
    "                }\n",
    "    tempo_data = {}\n",
    "    for seg_key, seg in segment_ax.items():\n",
    "        \n",
    "        sensor_onsets = ctempo.binary_to_peak(seg, peak_duration=0.1)\n",
    "\n",
    "        tempogram_ab, tempogram_raw, time_axis_seconds, tempo_axis_bpm = ctempo.compute_tempogram(sensor_onsets, fps, \n",
    "                                                                        window_length=window_size, hop_size=hop_size, tempi=tempi_range)\n",
    "        \n",
    "\n",
    "        tempo_data_maxmethod = ctempo.dance_beat_tempo_estimation_maxmethod(tempogram_ab[0], tempogram_raw[0], fps, \n",
    "                                                        novelty_length, window_size, hop_size, tempi_range)\n",
    "    \n",
    "        tempo_data[seg_key] = tempo_data_maxmethod\n",
    "        \n",
    "        estimated_bpm_per_window = tempo_data_maxmethod[\"bpm_arr\"]\n",
    "        magnitude_per_window = tempo_data_maxmethod[\"mag_arr\"]\n",
    "        \n",
    "        tempo_avg = np.round(np.average(estimated_bpm_per_window), 2)     # mean\n",
    "        tempo_mode = stats.mode(estimated_bpm_per_window.flatten())[0]        # \n",
    "        tempo_median = np.median(estimated_bpm_per_window.flatten())\n",
    "\n",
    "        # Append the rows to the DataFrame\n",
    "        result[seg_key][\"filename\"].append(filename.strip(\".pkl\"))\n",
    "        result[seg_key][\"dance_genre\"].append(dance_genre)\n",
    "        result[seg_key][\"situation\"].append(situation)\n",
    "        result[seg_key][\"camera_id\"].append(camera_id)\n",
    "        result[seg_key][\"dancer_id\"].append(dancer_id)\n",
    "        result[seg_key][\"music_id\"].append(music_id)\n",
    "        result[seg_key][\"choreo_id\"].append(choreo_id)\n",
    "        result[seg_key][\"music_tempo\"].append(aist_tempo[music_id])\n",
    "        result[seg_key][\"estimated_bpm_per_window\"].append(estimated_bpm_per_window)\n",
    "        result[seg_key][\"magnitude_per_window\"].append(magnitude_per_window)\n",
    "        result[seg_key][\"bpm_avg\"].append(tempo_avg)\n",
    "        result[seg_key][\"bpm_mode\"].append(tempo_mode)\n",
    "        result[seg_key][\"bpm_median\"].append(tempo_median)\n",
    "\n",
    "    \n",
    "    count +=1\n",
    "print(\"total processed:\",count)    \n",
    "for seg_key in segment_keys:\n",
    "    \n",
    "    fname1 = f\"{metric}/{seg_key}_{mode}_W{w_sec}_H{h_sec}_{a}_{b}.pkl\"\n",
    "    fpath1 = os.path.join(save_dir, fname1)\n",
    "    df_seg = pd.DataFrame(result[seg_key])\n",
    "    df_seg.to_pickle(fpath1)\n",
    "    \n",
    "    # tempodata_fname = f\"tempo_data/{metric}/{seg_key}_{mode}_W{w_sec}_H{h_sec}_{a}_{b}_tempo_data.pkl\"\n",
    "    # fpath2 = os.path.join(save_dir, tempodata_fname)\n",
    "    # save_to_pickle(fpath2, tempo_data[seg_key])\n",
    "#     print(f\"Saved {fname1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Tempo - Tempogram combination method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = \"music_id_tempo.json\"\n",
    "with open(json_filename, \"r\") as file:\n",
    "    aist_tempo = json.load(file)\n",
    "    \n",
    "def create_dir(main_dir, tempo_dir):\n",
    "    # main_dir = \"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result\"\n",
    "    directories = [f\"{tempo_dir}/pos\", f\"{tempo_dir}/vel\", f\"{tempo_dir}/score\",\n",
    "                   f\"{tempo_dir}/tempo_data/pos\", f\"{tempo_dir}/tempo_data/vel\",]\n",
    "    \n",
    "    for dir_path in directories:\n",
    "        full_path = os.path.join(main_dir, dir_path)\n",
    "        os.makedirs(full_path, exist_ok=True)\n",
    "\n",
    "# --- Helper functions ---\n",
    "def best_alignment(x, f, fps):\n",
    "    \"\"\"Return normalized correlation (−1 to 1) and lag (sec) for x vs sine kernel at freq f.\"\"\"\n",
    "    x = np.asarray(x).flatten()\n",
    "    x = x - np.mean(x)\n",
    "\n",
    "    # Skip empty/constant signals early\n",
    "    if np.allclose(x, 0) or np.std(x) < 1e-8:\n",
    "        return 0.0, 0.0, np.zeros_like(x), np.arange(len(x)) / fps\n",
    "\n",
    "    # Reference sinusoid\n",
    "    sine = np.sin(2 * np.pi * f * np.arange(len(x)) / fps)\n",
    "    sine -= np.mean(sine)\n",
    "\n",
    "    denom = np.sqrt(np.sum(x**2) * np.sum(sine**2))\n",
    "    if denom < 1e-12:  # avoid div-by-zero\n",
    "        return 0.0, 0.0, np.zeros_like(x), np.arange(len(x)) / fps\n",
    "\n",
    "    corr = np.correlate(x, sine, mode=\"full\") / denom\n",
    "    lags = np.arange(-len(x) + 1, len(x)) / fps\n",
    "\n",
    "    best_idx = np.argmax(np.abs(corr))\n",
    "    best_corr = float(corr[best_idx])\n",
    "    best_lag = float(lags[best_idx])\n",
    "    return best_corr, best_lag, corr, lags\n",
    "\n",
    "\n",
    "  \n",
    "segment_keys = ['bothhand_y_bothfoot_y', \"leftfoot_xy_rightfoot_xy\", \"left_foot_res_right_foot_res\",\n",
    "                    \"lefthand_xy_righthand_xy\", \"left_hand_res_right_hand_res\", \"bothfoot_x_bothfoot_y\",\n",
    "                    \"bothhand_x_bothfoot_x\", \"bothhand_x_bothhand_y\", \"both_hand_res_both_foot_res\"]\n",
    "\n",
    "# segment_keys = ['adaptv_Bhandfoot_y', \"adaptv_LRfoot_xy\", \n",
    "#                     \"adaptv_LRhand_xy\",  \"adaptv_Bfoot_x_y\",\n",
    "#                     \"adaptv_Bhandfoot_x\", \"adaptv_Bhand_x_y\"]\n",
    "\n",
    "result ={ key:\n",
    "    {\"filename\": [],\n",
    "    \"dance_genre\": [],\n",
    "    \"situation\": [],\n",
    "    \"camera_id\": [],\n",
    "    \"dancer_id\": [],\n",
    "    \"music_id\": [],\n",
    "    \"choreo_id\": [],\n",
    "    \"music_tempo\": [],\n",
    "    \"median_bpm_per_tempogram\": [],\n",
    "    \"global_tempo\": [],\n",
    "\n",
    "} for key in segment_keys }\n",
    "\n",
    "fps = 60\n",
    "w_sec = 5\n",
    "h_sec = w_sec/2\n",
    "window_size = int(fps*w_sec)\n",
    "hop_size = int(fps*h_sec)\n",
    "\n",
    "a = 45; b =140\n",
    "tempi_range = np.arange(a,b,1)\n",
    "metric = \"pos\"\n",
    "mode = \"zero_uni\"\n",
    "\n",
    "main_dir = \"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result_adaptive\"\n",
    "create_dir(main_dir, f\"tempo_{a}_{b}\")\n",
    "\n",
    "save_dir = f\"./saved_result_adaptive/tempo_{a}_{b}/\"\n",
    "f_path = \"./aist_dataset/aist_annotation/keypoints2d\"\n",
    "aist_filelist = os.listdir(f_path)\n",
    "\n",
    "pos_onset_dir = f\"./extracted_body_onsets_sept25/{metric}/\"\n",
    "# vel_onset_dir = f\"./extracted_body_onsets/vel/\"\n",
    "\n",
    "\n",
    "count= 0\n",
    "for idx, filename in enumerate(tqdm(aist_filelist)):\n",
    "    count +=1\n",
    "    file_info = filename.split(\"_\")\n",
    "    dance_genre = file_info[0] \n",
    "    situation = file_info[1] \n",
    "    camera_id = file_info[2] \n",
    "    dancer_id = file_info[3]\n",
    "    music_id = file_info[4]\n",
    "    choreo_id = file_info[5].strip(\".pkl\")\n",
    "    \n",
    "    test_path = os.path.join(pos_onset_dir, \"ax0\", f\"left_wrist_{mode}_{filename}\")\n",
    "    isExist = os.path.exists(test_path) \n",
    "    if not isExist:\n",
    "        continue\n",
    "    \n",
    "    left_hand_x  = load_pickle(os.path.join(pos_onset_dir, \"ax0\", f\"left_wrist_{mode}_{filename}\"))\n",
    "    left_hand_y  = load_pickle(os.path.join(pos_onset_dir, \"ax1\", f\"left_wrist_{mode}_{filename}\"))\n",
    "\n",
    "    right_hand_x = load_pickle(os.path.join(pos_onset_dir, \"ax0\", f\"right_wrist_{mode}_{filename}\"))\n",
    "    right_hand_y = load_pickle(os.path.join(pos_onset_dir, \"ax1\", f\"right_wrist_{mode}_{filename}\"))\n",
    "\n",
    "    left_foot_x  = load_pickle(os.path.join(pos_onset_dir, \"ax0\", f\"left_ankle_{mode}_{filename}\"))\n",
    "    left_foot_y  = load_pickle(os.path.join(pos_onset_dir, \"ax1\", f\"left_ankle_{mode}_{filename}\"))\n",
    "\n",
    "    right_foot_x = load_pickle(os.path.join(pos_onset_dir, \"ax0\", f\"right_ankle_{mode}_{filename}\"))\n",
    "    right_foot_y = load_pickle(os.path.join(pos_onset_dir, \"ax1\", f\"right_ankle_{mode}_{filename}\"))\n",
    "\n",
    "    novelty_length = left_hand_x['raw_signal'].shape[0]\n",
    "\n",
    "    #### Filtering Onsets ####\n",
    "\n",
    "    key = 'sensor_onsets'  # or 'sensor_abs_vel_filtered', depending on your data\n",
    "    thres = 0.2            # time threshold\n",
    "\n",
    "    # Position-based filtered onsets\n",
    "    bothhand_x = ctempo.filter_dir_onsets_by_threshold((left_hand_x[key] + right_hand_x[key]), threshold_s=thres, fps=fps)\n",
    "    bothhand_y = ctempo.filter_dir_onsets_by_threshold((left_hand_y[key] + right_hand_y[key]), threshold_s=thres, fps=fps)\n",
    "\n",
    "    bothfoot_x = ctempo.filter_dir_onsets_by_threshold((left_foot_x[key] + right_foot_x[key]), threshold_s=thres, fps=fps)\n",
    "    bothfoot_y = ctempo.filter_dir_onsets_by_threshold((left_foot_y[key] + right_foot_y[key]), threshold_s=thres, fps=fps)\n",
    "\n",
    "    lefthand_xy = ctempo.filter_dir_onsets_by_threshold((left_hand_x[key] + left_hand_y[key]), threshold_s=thres, fps=fps)\n",
    "    righthand_xy = ctempo.filter_dir_onsets_by_threshold((right_hand_x[key] + right_hand_y[key]), threshold_s=thres, fps=fps)\n",
    "\n",
    "    leftfoot_xy = ctempo.filter_dir_onsets_by_threshold((left_foot_x[key] + left_foot_y[key]), threshold_s=thres, fps=fps)\n",
    "    rightfoot_xy = ctempo.filter_dir_onsets_by_threshold((right_foot_x[key] + right_foot_y[key]), threshold_s=thres, fps=fps)\n",
    "\n",
    "    \n",
    "    # Resultant part\n",
    "    key1 = 'resultant_onsets'\n",
    "    left_hand_resultant  = load_pickle(os.path.join(pos_onset_dir, \"resultant\", f\"left_wrist_{mode}_{filename}\"))\n",
    "    right_hand_resultant  = load_pickle(os.path.join(pos_onset_dir, \"resultant\", f\"right_wrist_{mode}_{filename}\"))\n",
    "\n",
    "    left_foot_resultant = load_pickle(os.path.join(pos_onset_dir, \"resultant\", f\"left_ankle_{mode}_{filename}\"))\n",
    "    right_foot_resultant = load_pickle(os.path.join(pos_onset_dir, \"resultant\", f\"right_ankle_{mode}_{filename}\"))\n",
    "    \n",
    "    both_hand_resultant = ctempo.filter_dir_onsets_by_threshold((left_hand_resultant[key1] + right_hand_resultant[key1]), threshold_s= thres, fps=fps)\n",
    "    both_foot_resultant = ctempo.filter_dir_onsets_by_threshold((left_foot_resultant[key1] + right_foot_resultant[key1]), threshold_s= thres, fps=fps)\n",
    "\n",
    "    \n",
    "\n",
    "    adap_map = {\n",
    "    '1': [bothhand_y,          bothfoot_y,          'bothhand_y_bothfoot_y'],\n",
    "    '2': [leftfoot_xy,         rightfoot_xy,        'leftfoot_xy_rightfoot_xy'],\n",
    "    '3': [left_foot_resultant, right_foot_resultant,'left_foot_res_right_foot_res'],\n",
    "    '4': [lefthand_xy,         righthand_xy,        'lefthand_xy_righthand_xy'],\n",
    "    '5': [left_hand_resultant, right_hand_resultant,'left_hand_res_right_hand_res'],\n",
    "    '6': [bothfoot_x,          bothfoot_y,          'bothfoot_x_bothfoot_y'],\n",
    "    '7': [bothhand_x,          bothfoot_x,          'bothhand_x_bothfoot_x'],\n",
    "    '8': [bothhand_x,          bothhand_y,          'bothhand_x_bothhand_y'],\n",
    "    '9': [both_hand_resultant, both_foot_resultant, 'both_hand_res_both_foot_res'],\n",
    "    '10':[bothhand_y, bothfoot_y, torso_y,          'bothhand_y_bothfoot_y_torso_y'],\n",
    "    }\n",
    "    \n",
    "    combined_segment_ax = {'bothhand_y_bothfoot_y': [bothhand_y, bothfoot_y]}\n",
    "    \n",
    "    for nid, _ in adap_map.items():\n",
    "        data_pair, tag = adap_map[nid][0:2], adap_map[nid][2]\n",
    "\n",
    "        anchor1 = ctempo.binary_to_peak(data_pair[0], peak_duration=0.1)\n",
    "        anchor2 = ctempo.binary_to_peak(data_pair[1], peak_duration=0.1)\n",
    "        anchors = [anchor1, anchor2]\n",
    "        \n",
    "        # Compute tempograms for each sensor onset sequence\n",
    "        tempogram_ab1, tempogram_raw1, _, _ = ctempo.compute_tempogram(anchor1, fps, \n",
    "                                            window_length=window_size, hop_size=hop_size, tempi=tempi_range)\n",
    "\n",
    "        tempogram_ab2, tempogram_raw2, _, _ = ctempo.compute_tempogram(anchor2, fps, \n",
    "                                            window_length=window_size, hop_size=hop_size, tempi=tempi_range)\n",
    "        \n",
    "        \n",
    "        tempograms_raw = [tempogram_raw1, tempogram_raw2]     \n",
    "        tempograms_abs = [tempogram_ab1, tempogram_ab2]    # abs of tempogram_raw\n",
    "\n",
    "        \n",
    "        tempo_data = ctempo.dance_tempo_estimation_multi(tempograms_abs, tempograms_raw, anchors, fps, \n",
    "                                                        novelty_length, window_size, hop_size, tempi_range)\n",
    "        \n",
    "        \n",
    "\n",
    "        #################\n",
    "        #################\n",
    "        # reference_tempo = aist_tempo[music_id]\n",
    "        # test_frequencies = []\n",
    "        # for idx in range(2):\n",
    "        #     fq = np.round(tempo_data[idx][\"median_tempo\"]/60, 2)  # in Hz\n",
    "        #     test_frequencies.append(fq)\n",
    "        #     med_tempos= tempo_data[idx]['median_tempo']\n",
    "\n",
    "        # sensors = [anchor1, anchor2]\n",
    "        # sensor_names = [\"hand\", \"foot\"]\n",
    "\n",
    "        # # N = len(sensor_onsets1)\n",
    "        # # t = np.arange(N) / fps\n",
    "\n",
    "\n",
    "        # results = {name: {} for name in sensor_names}\n",
    "        # best_global = {\"freq\": None, \"sensor\": None, \"corr\": 0.0, \"lag\": None}\n",
    "\n",
    "        # for f in test_frequencies:\n",
    "        #     for name, x in zip(sensor_names, sensors):\n",
    "        #         best_corr, best_lag, corr, lags = best_alignment(x, f, fps)\n",
    "        #         results[name][f] = (best_corr, best_lag)\n",
    "\n",
    "        #         if abs(best_corr) > abs(best_global[\"corr\"]):\n",
    "        #             best_global.update({\"freq\": f, \"sensor\": name, \"corr\": best_corr, \"lag\": best_lag})\n",
    "        \n",
    "        # if best_global['freq'] is None:\n",
    "        #     gtempo = med_tempos\n",
    "        # else:    \n",
    "        #     gtempo = np.round(best_global['freq']*60, 2)  # in BPM\n",
    "        #####################\n",
    "        result[tag][\"filename\"].append(filename.strip(\".pkl\"))\n",
    "        result[tag][\"dance_genre\"].append(dance_genre)\n",
    "        result[tag][\"situation\"].append(situation)\n",
    "        result[tag][\"camera_id\"].append(camera_id)\n",
    "        result[tag][\"dancer_id\"].append(dancer_id)\n",
    "        result[tag][\"music_id\"].append(music_id)\n",
    "        result[tag][\"choreo_id\"].append(choreo_id)\n",
    "        result[tag][\"music_tempo\"].append(aist_tempo[music_id])\n",
    "        result[tag][\"median_bpm_per_tempogram\"].append(0)\n",
    "        result[tag][\"global_tempo\"].append(tempo_data['gtempo'])\n",
    "\n",
    "\n",
    "# for seg_key in segment_keys: \n",
    "#     fname1 = f\"{metric}/{seg_key}_{mode}_W{w_sec}_H{h_sec}_{a}_{b}.pkl\"\n",
    "#     fpath1 = os.path.join(save_dir, fname1)\n",
    "#     df_seg = pd.DataFrame(result[seg_key])\n",
    "#     df_seg.to_pickle(fpath1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval import compute_dts\n",
    "\n",
    "\n",
    "a, b = 45, 140\n",
    "root = \"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result_adaptive\"\n",
    "pth_pos = f\"{root}/tempo_{a}_{b}_torso/pos\"\n",
    "acc = {}\n",
    "\n",
    "\n",
    "for fname in os.listdir(pth_pos):\n",
    "    \n",
    "    if \"zero_bi\" in fname:\n",
    "        continue\n",
    "    \n",
    "    tag = fname.split(\"_zero_uni\")[0]\n",
    "    data = load_pickle(f\"{pth_pos}/{fname}\")\n",
    "    ref  = data[\"music_tempo\"].to_numpy()\n",
    "    accuracy, hit_idx, ref_hit_bpm = compute_dts(ref, data[\"global_tempo\"].to_numpy(), tau= 0.13, mode=\"one\")\n",
    "    \n",
    "    print(fname)    \n",
    "    print(f\"Overall Accuracy for {tag}: {accuracy:.2f} %\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with torso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1510/1510 [00:58<00:00, 25.71it/s]\n"
     ]
    }
   ],
   "source": [
    "json_filename = \"music_id_tempo.json\"\n",
    "with open(json_filename, \"r\") as file:\n",
    "    aist_tempo = json.load(file)\n",
    "    \n",
    "def create_dir(main_dir, tempo_dir):\n",
    "    # main_dir = \"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result\"\n",
    "    directories = [f\"{tempo_dir}/pos\", f\"{tempo_dir}/vel\", f\"{tempo_dir}/score\",\n",
    "                   f\"{tempo_dir}/tempo_data/pos\", f\"{tempo_dir}/tempo_data/vel\",]\n",
    "    \n",
    "    for dir_path in directories:\n",
    "        full_path = os.path.join(main_dir, dir_path)\n",
    "        os.makedirs(full_path, exist_ok=True)\n",
    "\n",
    "# --- Helper functions ---\n",
    "def best_alignment(x, f, fps):\n",
    "    \"\"\"Return normalized correlation (−1 to 1) and lag (sec) for x vs sine kernel at freq f.\"\"\"\n",
    "    x = np.asarray(x).flatten()\n",
    "    x = x - np.mean(x)\n",
    "\n",
    "    # Skip empty/constant signals early\n",
    "    if np.allclose(x, 0) or np.std(x) < 1e-8:\n",
    "        return 0.0, 0.0, np.zeros_like(x), np.arange(len(x)) / fps\n",
    "\n",
    "    # Reference sinusoid\n",
    "    sine = np.sin(2 * np.pi * f * np.arange(len(x)) / fps)\n",
    "    sine -= np.mean(sine)\n",
    "\n",
    "    denom = np.sqrt(np.sum(x**2) * np.sum(sine**2))\n",
    "    if denom < 1e-12:  # avoid div-by-zero\n",
    "        return 0.0, 0.0, np.zeros_like(x), np.arange(len(x)) / fps\n",
    "\n",
    "    corr = np.correlate(x, sine, mode=\"full\") / denom\n",
    "    lags = np.arange(-len(x) + 1, len(x)) / fps\n",
    "\n",
    "    best_idx = np.argmax(np.abs(corr))\n",
    "    best_corr = float(corr[best_idx])\n",
    "    best_lag = float(lags[best_idx])\n",
    "    return best_corr, best_lag, corr, lags\n",
    "\n",
    "\n",
    "        \n",
    "segment_keys = ['adaptv_Bhandfoot_y']\n",
    "\n",
    "# segment_keys = ['adaptv_Bhandfoot_y', \"adaptv_LRfoot_xy\", \n",
    "#                     \"adaptv_LRhand_xy\",  \"adaptv_Bfoot_x_y\",\n",
    "#                     \"adaptv_Bhandfoot_x\", \"adaptv_Bhand_x_y\"]\n",
    "\n",
    "result ={ key:\n",
    "    {\"filename\": [],\n",
    "    \"dance_genre\": [],\n",
    "    \"situation\": [],\n",
    "    \"camera_id\": [],\n",
    "    \"dancer_id\": [],\n",
    "    \"music_id\": [],\n",
    "    \"choreo_id\": [],\n",
    "    \"music_tempo\": [],\n",
    "    \"median_bpm_per_tempogram\": [],\n",
    "    \"global_tempo\": [],\n",
    "\n",
    "} for key in segment_keys }\n",
    "\n",
    "fps = 60\n",
    "w_sec = 5\n",
    "h_sec = w_sec/2\n",
    "window_size = int(fps*w_sec)\n",
    "hop_size = int(fps*h_sec)\n",
    "\n",
    "a = 45; b =140\n",
    "tempi_range = np.arange(a,b,1)\n",
    "metric = \"pos\"\n",
    "mode = \"zero_uni\"\n",
    "\n",
    "main_dir = \"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result_adaptive\"\n",
    "create_dir(main_dir, f\"tempo_{a}_{b}_torso\")\n",
    "\n",
    "save_dir = f\"./saved_result_adaptive/tempo_{a}_{b}_torso/\"\n",
    "f_path = \"./aist_dataset/aist_annotation/keypoints2d\"\n",
    "aist_filelist = os.listdir(f_path)\n",
    "\n",
    "pos_onset_dir = f\"./extracted_body_onsets_sept25/{metric}/\"\n",
    "# vel_onset_dir = f\"./extracted_body_onsets/vel/\"\n",
    "\n",
    "\n",
    "count= 0\n",
    "for fidx, filename in enumerate(tqdm(aist_filelist)):\n",
    "    count +=1\n",
    "    file_info = filename.split(\"_\")\n",
    "    dance_genre = file_info[0] \n",
    "    situation = file_info[1] \n",
    "    camera_id = file_info[2] \n",
    "    dancer_id = file_info[3]\n",
    "    music_id = file_info[4]\n",
    "    choreo_id = file_info[5].strip(\".pkl\")\n",
    "    \n",
    "    test_path = os.path.join(pos_onset_dir, \"ax0\", f\"left_wrist_{mode}_{filename}\")\n",
    "    isExist = os.path.exists(test_path) \n",
    "    if not isExist:\n",
    "        continue\n",
    "\n",
    "    left_hand_y  = load_pickle(os.path.join(pos_onset_dir, \"ax1\", f\"left_wrist_{mode}_{filename}\"))\n",
    "    right_hand_y = load_pickle(os.path.join(pos_onset_dir, \"ax1\", f\"right_wrist_{mode}_{filename}\"))\n",
    "\n",
    "    left_foot_y  = load_pickle(os.path.join(pos_onset_dir, \"ax1\", f\"left_ankle_{mode}_{filename}\"))\n",
    "    right_foot_y = load_pickle(os.path.join(pos_onset_dir, \"ax1\", f\"right_ankle_{mode}_{filename}\"))\n",
    "    \n",
    "    # torso_y = load_pickle(os.path.join(\"aist_tempo_est/extracted_body_onsets_sept25/torso\", f\"torso_{mode}_{filename}\"))\n",
    "    torso_y = load_pickle(os.path.join(\"/itf-fi-ml/home/sagardu/aist_tempo_COM/aist_tempo_est/extracted_body_onsets/pos/ax1\", f\"torso_{mode}_{filename}\"))\n",
    "\n",
    "    novelty_length = left_hand_y['raw_signal'].shape[0]\n",
    "\n",
    "    #### Filtering Onsets ####\n",
    "\n",
    "    key = 'sensor_onsets'  # or 'sensor_abs_vel_filtered', depending on your data\n",
    "    thres = 0.2            # time threshold\n",
    "\n",
    "    # Position-based filtered onsets\n",
    "    \n",
    "    bothhand_y = ctempo.filter_dir_onsets_by_threshold((left_hand_y[key] + right_hand_y[key]), threshold_s=thres, fps=fps)\n",
    "    bothfoot_y = ctempo.filter_dir_onsets_by_threshold((left_foot_y[key] + right_foot_y[key]), threshold_s=thres, fps=fps)\n",
    "    \n",
    "\n",
    "    adap_map = {\n",
    "    '1': [bothhand_y, bothfoot_y, torso_y,          'adaptv_Bhandfoot_y'],\n",
    "\n",
    "}\n",
    "    \n",
    "    # nid = \"8\"\n",
    "    for nid, _ in adap_map.items():\n",
    "        data_pair, tag = adap_map[nid][0:3], adap_map[nid][3]\n",
    "        ###########################################################################################    \n",
    "        sensor_onsets1 = ctempo.binary_to_peak(data_pair[0], peak_duration=0.1)\n",
    "        sensor_onsets2 = ctempo.binary_to_peak(data_pair[1], peak_duration=0.1)\n",
    "        sensor_onsets3 = ctempo.binary_to_peak(data_pair[2]['sensor_onsets'], peak_duration=0.1)\n",
    "\n",
    "        # Compute tempograms for each sensor onset sequence\n",
    "        tempogram_ab1, tempogram_raw1, _, _ = ctempo.compute_tempogram(sensor_onsets1, fps, \n",
    "                                            window_length=window_size, hop_size=hop_size, tempi=tempi_range)\n",
    "\n",
    "        tempogram_ab2, tempogram_raw2, _, _ = ctempo.compute_tempogram(sensor_onsets2, fps, \n",
    "                                            window_length=window_size, hop_size=hop_size, tempi=tempi_range)\n",
    "        \n",
    "        tempogram_ab3, tempogram_raw3, _, _ = ctempo.compute_tempogram(sensor_onsets3, fps, \n",
    "                                            window_length=window_size, hop_size=hop_size, tempi=tempi_range)\n",
    "        \n",
    "        tempogram_raw = [tempogram_raw1, tempogram_raw2, tempogram_raw3]     \n",
    "        tempogram_abs = [tempogram_ab1, tempogram_ab2, tempogram_ab3]    # abs of tempogram_raw\n",
    "        \n",
    "\n",
    "\n",
    "        tempo_data = ctempo.dance_tempo_estimation(tempogram_abs, tempogram_raw, fps, \n",
    "                                                        novelty_length, window_size, hop_size, tempi_range)\n",
    "        \n",
    "        #################\n",
    "        reference_tempo = aist_tempo[music_id]\n",
    "        test_frequencies = []\n",
    "        for idx in range(3):\n",
    "            fq = np.round(tempo_data[idx][\"median_tempo\"]/60, 2)  # in Hz\n",
    "            test_frequencies.append(fq)\n",
    "            med_tempos= tempo_data[idx]['median_tempo']\n",
    "\n",
    "        sensors = [sensor_onsets1, sensor_onsets2, sensor_onsets3]\n",
    "        sensor_names = [\"hand\", \"foot\", \"torso\"]\n",
    "\n",
    "        # N = len(sensor_onsets1)\n",
    "        # t = np.arange(N) / fps\n",
    "\n",
    "\n",
    "        results = {name: {} for name in sensor_names}\n",
    "        best_global = {\"freq\": None, \"sensor\": None, \"corr\": 0.0, \"lag\": None}\n",
    "\n",
    "        for f in test_frequencies:\n",
    "            for name, x in zip(sensor_names, sensors):\n",
    "                best_corr, best_lag, corr, lags = best_alignment(x, f, fps)\n",
    "                results[name][f] = (best_corr, best_lag)\n",
    "\n",
    "                if abs(best_corr) > abs(best_global[\"corr\"]):\n",
    "                    best_global.update({\"freq\": f, \"sensor\": name, \"corr\": best_corr, \"lag\": best_lag})\n",
    "        \n",
    "        gtempo = np.round(best_global['freq']*60, 2)  # in BPM\n",
    "        #####################\n",
    "        # print(\"reference_tempo:\", reference_tempo, \" BPM \")\n",
    "        # print(f\"Global Tempo: {gtempo} BPM \")\n",
    "        \n",
    "    # if fidx==2:\n",
    "        # break    \n",
    "        \n",
    "\n",
    "\n",
    "        #############################################################################################\n",
    "        # Append the rows to the DataFrame\n",
    "        result[tag][\"filename\"].append(filename.strip(\".pkl\"))\n",
    "        result[tag][\"dance_genre\"].append(dance_genre)\n",
    "        result[tag][\"situation\"].append(situation)\n",
    "        result[tag][\"camera_id\"].append(camera_id)\n",
    "        result[tag][\"dancer_id\"].append(dancer_id)\n",
    "        result[tag][\"music_id\"].append(music_id)\n",
    "        result[tag][\"choreo_id\"].append(choreo_id)\n",
    "        result[tag][\"music_tempo\"].append(aist_tempo[music_id])\n",
    "        result[tag][\"median_bpm_per_tempogram\"].append(med_tempos)\n",
    "        result[tag][\"global_tempo\"].append(gtempo)\n",
    "\n",
    "\n",
    "# fpath1 = os.path.join(save_dir, fname1)\n",
    "# df_seg = pd.DataFrame(result)\n",
    "# df_seg.to_pickle(fpath1)\n",
    "\n",
    "for seg_key in segment_keys:\n",
    "    \n",
    "    fname1 = f\"{metric}/{seg_key}_{mode}_W{w_sec}_H{h_sec}_{a}_{b}.pkl\"\n",
    "    fpath1 = os.path.join(save_dir, fname1)\n",
    "    df_seg = pd.DataFrame(result[seg_key])\n",
    "    df_seg.to_pickle(fpath1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaptv_Bhandfoot_y_zero_uni_W5_H2.5_45_140.pkl\n",
      "Overall Accuracy for adaptv_Bhandfoot_y: 73.38 %\n"
     ]
    }
   ],
   "source": [
    "from utils.eval import compute_dts\n",
    "\n",
    "\n",
    "a, b = 45, 140\n",
    "root = \"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result_adaptive\"\n",
    "pth_pos = f\"{root}/tempo_{a}_{b}_torso/pos\"\n",
    "acc = {}\n",
    "\n",
    "\n",
    "for fname in os.listdir(pth_pos):\n",
    "    print(fname)\n",
    "    if \"zero_bi\" in fname:\n",
    "        continue\n",
    "    \n",
    "    tag = fname.split(\"_zero_uni\")[0]\n",
    "    data = load_pickle(f\"{pth_pos}/{fname}\")\n",
    "    ref  = data[\"music_tempo\"].to_numpy()\n",
    "    accuracy, hit_idx, ref_hit_bpm = compute_dts(ref, data[\"global_tempo\"].to_numpy(), tau= 0.13, mode=\"one\")\n",
    "        \n",
    "print(f\"Overall Accuracy for {tag}: {accuracy:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ===== Function to compute best alignment =====\n",
    "def best_alignment(x, f, fps):\n",
    "    \"\"\"Return normalized correlation (−1 to 1) and lag (sec) for x vs sine kernel at freq f.\"\"\"\n",
    "    x = np.asarray(x).flatten()\n",
    "    x = x - np.mean(x)\n",
    "\n",
    "    # Skip empty/constant signals early\n",
    "    if np.allclose(x, 0) or np.std(x) < 1e-8:\n",
    "        return 0.0, 0.0, np.zeros_like(x), np.arange(len(x)) / fps\n",
    "\n",
    "    # Reference sinusoid\n",
    "    sine = np.sin(2 * np.pi * f * np.arange(len(x)) / fps)\n",
    "    sine -= np.mean(sine)\n",
    "\n",
    "    denom = np.sqrt(np.sum(x**2) * np.sum(sine**2))\n",
    "    if denom < 1e-12:  # avoid div-by-zero\n",
    "        return 0.0, 0.0, np.zeros_like(x), np.arange(len(x)) / fps\n",
    "\n",
    "    corr = np.correlate(x, sine, mode=\"full\") / denom\n",
    "    lags = np.arange(-len(x) + 1, len(x)) / fps\n",
    "\n",
    "    best_idx = np.argmax(np.abs(corr))\n",
    "    best_corr = float(corr[best_idx])\n",
    "    best_lag = float(lags[best_idx])\n",
    "    return best_corr, best_lag, corr, lags\n",
    "\n",
    "test_frequencies = []\n",
    "for idx in range(3):\n",
    "    fq = np.round(tempo_data[idx][\"median_tempo\"]/60, 2)  # in Hz\n",
    "    test_frequencies.append(fq)\n",
    "     \n",
    "\n",
    "\n",
    "sensors = [sensor_onsets1, sensor_onsets2, sensor_onsets3]\n",
    "sensor_names = [\"hand\", \"foot\", \"torso\"]\n",
    "\n",
    "N = len(sensor_onsets1)\n",
    "t = np.arange(N) / fps\n",
    "\n",
    "\n",
    "results = {name: {} for name in sensor_names}\n",
    "best_global = {\"freq\": None, \"sensor\": None, \"corr\": 0.0, \"lag\": None}\n",
    "\n",
    "for f in test_frequencies:\n",
    "    for name, x in zip(sensor_names, sensors):\n",
    "        best_corr, best_lag, corr, lags = best_alignment(x, f, fps)\n",
    "        results[name][f] = (best_corr, best_lag)\n",
    "        # print(f\"{name}@{f:.2f}Hz corr={best_corr:.5f}, lag={best_lag:.3f}\")\n",
    "\n",
    "        if abs(best_corr) > abs(best_global[\"corr\"]):\n",
    "            best_global.update({\"freq\": f, \"sensor\": name, \"corr\": best_corr, \"lag\": best_lag})\n",
    "\n",
    "if best_global[\"freq\"] is not None:\n",
    "    print(\"\\n=== GLOBAL TEMPO ESTIMATION ===\")\n",
    "    print(\"Reference tempo: {:.2f} BPM\".format(reference_tempo))\n",
    "    print(f\"Best frequency: {best_global['freq']:.3f} Hz (≈ {best_global['freq']*60:.1f} BPM)\")\n",
    "    # print(f\"From sensor: {best_global['sensor']}\")\n",
    "    # print(f\"Correlation: {best_global['corr']:.4f}\")\n",
    "    # print(f\"Lag: {best_global['lag']:.4f} s\")\n",
    "else:\n",
    "    print(\"\\nNo valid best frequency found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Print summary =====\n",
    "for name in sensor_names:\n",
    "    print(f\"\\n{name}:\")\n",
    "    for f in test_frequencies:\n",
    "        corr, lag = results[name][f]\n",
    "        print(f\"  {f:.2f} Hz → corr={corr:.4f}, lag={lag:.4f}s\")\n",
    "\n",
    "print(\"\\n=== GLOBAL TEMPO ESTIMATION ===\")\n",
    "print(f\"Best frequency: {best_global['freq']:.3f} Hz (≈ {best_global['freq']*60:.1f} BPM)\")\n",
    "print(f\"From sensor: {best_global['sensor']}\")\n",
    "print(f\"Correlation: {best_global['corr']:.4f}\")\n",
    "print(f\"Lag: {best_global['lag']:.4f} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
