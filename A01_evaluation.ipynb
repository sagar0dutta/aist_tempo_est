{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077da41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.eval import *\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b377e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_single(a, b, mode, anchor_type, tolerance=0.13):\n",
    "\n",
    "    segment_keys = [\n",
    "                    \"torso_y\",\n",
    "                    \"left_hand_x\", \"right_hand_x\", \"left_hand_y\", \"right_hand_y\",   # singular\n",
    "                    \"left_foot_x\", \"right_foot_x\", \"left_foot_y\", \"right_foot_y\",   # singular\n",
    "                    \n",
    "                    \"lefthand_xy\", \"righthand_xy\", \"leftfoot_xy\", \"rightfoot_xy\",   # singular | 35, 40, 34, 36\n",
    "                    \"left_hand_resultant\", \"right_hand_resultant\", \"left_foot_resultant\", \"right_foot_resultant\",   # singular | 18,20,17,17 %\n",
    "                    \n",
    "                    \"both_hand_x\", \"both_hand_y\", \"both_foot_x\", \"both_foot_y\",\n",
    "                     \"both_hand_resultant\", \"both_foot_resultant\", # resultant of x and y onsets\n",
    "                    \n",
    "                    \"bothhand_x_bothfoot_x\", \"bothhand_y_bothfoot_y\",\n",
    "                    \"lefthand_xy_righthand_xy\", \"leftfoot_xy_rightfoot_xy\",\n",
    "                    \"bothhand_x_bothhand_y\", \"bothfoot_x_bothfoot_y\", \n",
    "                    ] \n",
    "    \n",
    "    score_data = {}\n",
    "    json_data = {}\n",
    "    output_path = f\"./tempo_estimation_output/tempo_{a}_{b}/\"\n",
    "\n",
    "    score_data[\"bpm_median\"] = {}\n",
    "    json_data[\"bpm_median\"] = {}\n",
    "    \n",
    "    for idx, f_name in enumerate(segment_keys):\n",
    "        \n",
    "        f_path = output_path + f\"{anchor_type}/{f_name}_{mode}.pkl\"        # _W{w_sec}_H{h_sec}_{a}_{b}\n",
    "        df_ax = pd.read_pickle(f_path)\n",
    "\n",
    "        ref = df_ax[\"music_tempo\"].to_numpy()\n",
    "        dts_acc, hit_idx, ref_hit_bpm = compute_dts(ref, np.asarray(df_ax[\"bpm_median\"]), tau=tolerance, mode = \"one\")\n",
    "        \n",
    "        json_data[\"bpm_median\"][f_name] = {\"accuracy\": np.round(dts_acc, 2),\n",
    "                                            \"hit_index\": hit_idx,\n",
    "                                            \"ref_hit_bpm\": ref_hit_bpm}\n",
    "                            \n",
    "\n",
    "    #### Save the score data to a pickle file\n",
    "    save_dir = os.path.join(output_path, \"eval_data\", \"single\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    fname = f\"{anchor_type}_{mode}.pkl\"\n",
    "    fpath = os.path.join(save_dir, fname)\n",
    "    save_to_pickle(fpath, score_data)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "a = 45; b= 140\n",
    "mode = \"uni\"\n",
    "w_sec = 5; h_sec = w_sec/2\n",
    "\n",
    "\n",
    "jdata1 = evaluation_single(a, b, mode, \"anchor_zero\", tolerance=0.13)    # overall acc1 per body segment\n",
    "jdata2 = evaluation_single(a, b, mode, \"anchor_peak\", tolerance=0.13)    # overall acc1 per body segment\n",
    "jdata3 = evaluation_single(a, b, mode, \"anchor_energy\",tolerance=0.13)    # overall acc1 per body segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76406adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_segment = [\n",
    "    \"bothhand_y_bothfoot_y\",\n",
    "    \"leftfoot_xy_rightfoot_xy\",\n",
    "    \"left_foot_res_right_foot_res\",\n",
    "    \"lefthand_xy_righthand_xy\",\n",
    "    \"left_hand_res_right_hand_res\",\n",
    "    \"bothfoot_x_bothfoot_y\",\n",
    "    \"bothhand_x_bothfoot_x\",\n",
    "    \"bothhand_x_bothhand_y\",\n",
    "    \"both_hand_res_both_foot_res\",\n",
    "    \"bothhand_y_bothfoot_y_torso_y\",\n",
    "]\n",
    "\n",
    "\n",
    "def collect_accuracies(anchor_type, mode, a, b, tolerance=0.13):\n",
    "    acc = {}\n",
    "    json_data = {}\n",
    "    root_dir = \"./tempo_estimation_output\"\n",
    "    anchor_dir = os.path.join(root_dir, f\"tempo_{a}_{b}\", \"multi\", anchor_type)\n",
    "    \n",
    "    for seg in multi_segment:\n",
    "\n",
    "        file_name = f\"{seg}_{mode}.pkl\"\n",
    "        file_path = os.path.join(anchor_dir, file_name)\n",
    "        \n",
    "        data = load_pickle(file_path)\n",
    "        ref  = data[\"music_tempo\"].to_numpy()\n",
    "        accuracy, hit_idx, ref_hit_bpm = compute_dts(ref, data[\"gtempo\"].to_numpy(),\n",
    "                                            tau=tolerance, mode=\"one\")\n",
    "        \n",
    "        acc[seg] = round(accuracy, 2)\n",
    "        json_data[seg] = {\"acc\": accuracy, \"hit_idx\": hit_idx, \"ref_hit_bpm\": ref_hit_bpm}\n",
    "        \n",
    "\n",
    "    #### Save the score data to a pickle file\n",
    "    output_path = f\"./tempo_estimation_output/tempo_{a}_{b}/\"\n",
    "    save_dir = os.path.join(output_path, \"eval_data\", \"multi\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    fname = f\"{anchor_type}_{mode}.pkl\"\n",
    "    fpath = os.path.join(save_dir, fname)\n",
    "    save_to_pickle(fpath, json_data)\n",
    "    \n",
    "    return acc, json_data\n",
    "\n",
    "\n",
    "# path setup\n",
    "a, b = 45, 140\n",
    "\n",
    "accuracy_zero, _ = collect_accuracies(\"anchor_zero\", \"uni\",a,b, tolerance=0.13)\n",
    "accuracy_peak, _ = collect_accuracies(\"anchor_peak\", \"uni\",a,b, tolerance=0.13)\n",
    "accuracy_energy, _ = collect_accuracies(\"anchor_energy\", \"uni\",a,b, tolerance=0.13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6486246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dts_bon(\n",
    "    ref_bpm,\n",
    "    estimated_bpm,\n",
    "    tau=0.13,\n",
    "    mode=\"one\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Continuous Dance-Tempo Score (DTS), with support for\n",
    "    either single estimates (mode=\"one\") or multiple\n",
    "    candidates per frame (mode=\"many\").\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ref_bpm : array-like, shape (n,)\n",
    "        Ground-truth musical tempo in BPM.\n",
    "    estimated_bpm : \n",
    "        If mode=\"one\": array-like, shape (n,)\n",
    "        If mode=\"many\": iterable of length-n, each element\n",
    "                        is an iterable of candidate BPMs.\n",
    "    tau : float, optional\n",
    "        Tolerance in octaves (0.06 ≈ 4 %).\n",
    "    mode : {\"one\", \"many\"} \n",
    "        “one”: treat `estimated_bpm` as a flat sequence.\n",
    "        “many”: pick, for each i, the candidate closest to ref_bpm[i]. For best of two\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dts : ndarray, shape (n,)\n",
    "        Scores in [0, 1] (1 = perfect, 0 = miss ≥ τ octaves away).\n",
    "    e : ndarray, shape (n,)\n",
    "        Raw octave errors log₂(estimate/ref).\n",
    "    d : ndarray, shape (n,)\n",
    "        Wrapped distance to {-1, 0, +1} before clipping.\n",
    "    \"\"\"\n",
    "    ref_bpm = np.asarray(ref_bpm, dtype=float)\n",
    "\n",
    "    body_parts = [\"hand\", \"foot\", \"torso\"]\n",
    "\n",
    "    if mode == \"many\":\n",
    "        chosen = []\n",
    "        for i, cands in enumerate(estimated_bpm):  # e.g. (bpm_hand, bpm_foot, bpm_torso)\n",
    "            ref = ref_bpm[i]\n",
    "            diffs = [\n",
    "                min(abs(b - ref), abs(b - 0.5 * ref), abs(b - 2.0 * ref))\n",
    "                for b in cands\n",
    "            ]\n",
    "            idx_min = int(np.argmin(diffs))  # index of best match\n",
    "            chosen_bpm = cands[idx_min]\n",
    "            chosen_part = body_parts[idx_min]\n",
    "            chosen.append((chosen_bpm, chosen_part))\n",
    "\n",
    "    elif mode == \"one\":\n",
    "        chosen = [(float(b), None) for b in np.asarray(estimated_bpm, dtype=float)]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode!r}. Use 'one' or 'many'.\")\n",
    "\n",
    "    chosen_bpm = np.array([c[0] for c in chosen], dtype=float)\n",
    "    # DTS core ------------------------------------------------------\n",
    "    e = np.log2(chosen_bpm / ref_bpm)\n",
    "    # distance from nearest of -1, 0, +1\n",
    "    d = np.abs(e[:, None] - np.array([-1.0, 0.0, 1.0])).min(axis=1)\n",
    "    # clip by tolerance and convert to score\n",
    "    d_clip = np.minimum(d, tau)\n",
    "    dts    = 1.0 - d_clip / tau\n",
    "\n",
    "    accuracy = (dts > 0.0).mean() * 100\n",
    "    \n",
    "    # hits ----------------------------------------------------------\n",
    "    hit_mask = dts > 0.0          # inside ±tau band\n",
    "    hit_idx = np.nonzero(hit_mask)[0]\n",
    "    ref_hit_bpm = ref_bpm[hit_idx]\n",
    "    \n",
    "    return accuracy, hit_idx, ref_hit_bpm, chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318a220",
   "metadata": {},
   "source": [
    "## Evaluation: best of N strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452acf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_best_of_n(segment_names, a, b, mode, anchor_type, tolerance=0.13):\n",
    "    # Using both zero velocity and peak velocity\n",
    "    segment_names = [\"both_hand_y\", \"both_foot_y\"]  # example\n",
    "    \n",
    "    score_data = {}\n",
    "    json_data = {}\n",
    "    output_path = f\"./tempo_estimation_output/tempo_{a}_{b}/\"\n",
    "\n",
    "    for idx, segment in enumerate(segment_names):\n",
    "        # Build file paths for position and velocity data\n",
    "        read_file1 = output_path +  f\"{anchor_type}/{segment}_{mode}.pkl\"  \n",
    "        read_file2 = output_path +  f\"{anchor_type}/{segment}_{mode}.pkl\"  \n",
    "        read_file5 = output_path +  f\"{anchor_type}/{segment}_{mode}.pkl\"    # for reference tempo\n",
    "        \n",
    "        # Load the dataframes\n",
    "        df1 = pd.read_pickle(read_file1)\n",
    "        df2 = pd.read_pickle(read_file2)\n",
    "        df5 = pd.read_pickle(read_file5)   # for reference tempo\n",
    "        \n",
    "        # Build candidate BPM pairs (for positions) and quads (for positions and velocities)\n",
    "\n",
    "        bpm_candidates = []\n",
    "        for n in range(df1.shape[0]):\n",
    "            bpm1 = df1.iloc[n][\"bpm_median\"]   # hand (position)\n",
    "            bpm2 = df2.iloc[n][\"bpm_median\"]   # foot (position)\n",
    "            bpm5 = df5.iloc[n][\"bpm_median\"]   # torso (position) - not used here\n",
    "            \n",
    "            bpm_candidates.append((bpm1, bpm2, bpm5))     # , bpm5\n",
    "        \n",
    "            # music_tempo from df1 \n",
    "            ref = df1[\"music_tempo\"].to_numpy()\n",
    "            acc, hit_idx, ref_hit_bpm, chosen = compute_dts_bon(ref, bpm_candidates, tau=tolerance, mode = \"many\")\n",
    "\n",
    "        \n",
    "    json_data = {\"accuracy\": acc,\n",
    "                \"hits\": hit_idx,\n",
    "                \"hit_ref_bpm\": ref_hit_bpm,\n",
    "                \"chosen_bpm\": chosen,\n",
    "                }\n",
    "\n",
    "    ### Sace the score data to a pickle file\n",
    "    save_dir = os.path.join(output_path, \"eval_data\", \"best_of_n\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    fname = f\"{anchor_type}_{mode}.pkl\"\n",
    "    fpath = os.path.join(save_dir, fname)\n",
    "    save_to_pickle(fpath, json_data)\n",
    "        \n",
    "    return json_data, chosen, ref, hit_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c93f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_best_of_n(segment_names, a, b, mode, anchor_type, tolerance=0.13):\n",
    "    \"\"\"\n",
    "    Evaluate 'best-of-n' accuracy across multiple segments.\n",
    "\n",
    "    Args:\n",
    "        segment_names (list[str]): List of segment names (e.g., [\"both_hand_y\", \"both_foot_y\", \"torso_y\"])\n",
    "        a, b (int/float): Tempo range parameters\n",
    "        mode (str): Mode name (e.g., \"pos\", \"vel\")\n",
    "        anchor_type (str): Anchor type (e.g., \"anchor_zero\", \"anchor_peak\")\n",
    "        tolerance (float): Allowed tempo deviation (default 0.13)\n",
    "    \"\"\"\n",
    "    output_path = f\"./tempo_estimation_output/tempo_{a}_{b}/\"\n",
    "    score_data = {}\n",
    "    bpm_candidates = []\n",
    "\n",
    "    # Load all DataFrames dynamically for each segment\n",
    "    dfs = []\n",
    "    for seg in segment_names:\n",
    "        fpath = os.path.join(output_path, anchor_type, f\"{seg}_{mode}.pkl\")\n",
    "        dfs.append(pd.read_pickle(fpath))\n",
    "\n",
    "    # Assume all DataFrames are aligned (same rows for each recording)\n",
    "    num_rows = dfs[0].shape[0]\n",
    "    ref = dfs[0][\"music_tempo\"].to_numpy()  # Reference tempo (same across all)\n",
    "\n",
    "    # Build candidate BPM tuples across n segments\n",
    "    for i in range(num_rows):\n",
    "        bpm_tuple = tuple(df.iloc[i][\"bpm_median\"] for df in dfs)\n",
    "        bpm_candidates.append(bpm_tuple)\n",
    "\n",
    "    # Compute best-of-n accuracy\n",
    "    acc, hit_idx, ref_hit_bpm, chosen = compute_dts_bon(ref, bpm_candidates, tau=tolerance, mode=\"many\")\n",
    "\n",
    "    # Save results\n",
    "    json_data = {\n",
    "        \"accuracy\": acc,\n",
    "        \"hits\": hit_idx,\n",
    "        \"hit_ref_bpm\": ref_hit_bpm,\n",
    "        \"chosen_candidated_bpm\": chosen,\n",
    "    }\n",
    "\n",
    "    save_dir = os.path.join(output_path, \"eval_data\", \"best_of_n\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    fname = f\"{anchor_type}_{mode}.pkl\"\n",
    "    fpath = os.path.join(save_dir, fname)\n",
    "    save_to_pickle(fpath, json_data)\n",
    "\n",
    "    return json_data, chosen, ref, hit_idx\n",
    "\n",
    "segment_names = [\"both_hand_y\", \"both_foot_y\", \"torso_y\"]\n",
    "json_data, chosen, ref, hit_idx = eval_best_of_n(segment_names, 45, 140, \"uni\", \"anchor_zero\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1d093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               genre body_part  count\n",
      "2        Ballet Jazz     torso     55\n",
      "1        Ballet Jazz      hand     44\n",
      "0        Ballet Jazz      foot     37\n",
      "4              Break      hand     46\n",
      "3              Break      foot     31\n",
      "5              Break     torso     22\n",
      "7              House      hand     57\n",
      "8              House     torso     49\n",
      "6              House      foot     30\n",
      "11             Krump     torso     61\n",
      "10             Krump      hand     46\n",
      "9              Krump      foot     30\n",
      "14  LA style Hip-hop     torso     64\n",
      "13  LA style Hip-hop      hand     42\n",
      "12  LA style Hip-hop      foot     35\n",
      "17              Lock     torso     55\n",
      "16              Lock      hand     52\n",
      "15              Lock      foot     34\n",
      "20    Middle Hip-hop     torso     54\n",
      "19    Middle Hip-hop      hand     52\n",
      "18    Middle Hip-hop      foot     34\n",
      "22               Pop      hand     58\n",
      "23               Pop     torso     47\n",
      "21               Pop      foot     36\n",
      "26       Street Jazz     torso     57\n",
      "25       Street Jazz      hand     38\n",
      "24       Street Jazz      foot     34\n",
      "29             Waack     torso     64\n",
      "28             Waack      hand     47\n",
      "27             Waack      foot     30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "with open(\"genre_symbols_mapping.json\", \"r\") as file:\n",
    "    genre_name = json.load(file)\n",
    "\n",
    "\n",
    "output_path = f\"./tempo_estimation_output/tempo_{a}_{b}/\"\n",
    "fpath4 = os.path.join(output_path, f\"anchor_zero/left_hand_y_{mode}.pkl\")\n",
    "main_df = pd.read_pickle(fpath4)\n",
    "\n",
    "\n",
    "# Assuming chosen and main_df have the same length\n",
    "genre_part_map = defaultdict(list)\n",
    "\n",
    "for i, (bpm, part) in enumerate(chosen):\n",
    "    genre = main_df.loc[i, \"dance_genre\"]\n",
    "    genre_part_map[genre_name[genre]].append(part)\n",
    "\n",
    "\n",
    "# Convert to a DataFrame for easier counting\n",
    "genre_part_df = pd.DataFrame([\n",
    "    {\"genre\": genre, \"body_part\": part}\n",
    "    for genre, parts in genre_part_map.items()\n",
    "    for part in parts\n",
    "])\n",
    "\n",
    "# Count frequency of each body part per genre\n",
    "part_counts = (\n",
    "    genre_part_df.groupby([\"genre\", \"body_part\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .sort_values([\"genre\", \"count\"], ascending=[True, False])\n",
    ")\n",
    "print(part_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
