{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from compute_tempo_aist import *\n",
    "from aist_pos1s_script import *\n",
    "# coco={    \n",
    "# 0: \"nose\", 1: \"left_eye\", 2: \"right_eye\", 3: \"left_ear\",4: \"right_ear\",5: \"left_shoulder\",\n",
    "# 6: \"right_shoulder\",7: \"left_elbow\",8: \"right_elbow\",9: \"left_wrist\",10: \"right_wrist\",\n",
    "# 11: \"left_hip\",12: \"right_hip\",13: \"left_knee\",14: \"right_knee\",15: \"left_ankle\",16: \"right_ankle\",}  \n",
    "\n",
    "# # cp ./video/gKR_sBM_c01_d28_mKR3_ch03.mp4 ./\n",
    "\n",
    "\n",
    "# main_dir = \"/itf-fi-ml/home/sagardu/aist_tempo_est/optimization/saved_results/tempo_case_1\"\n",
    "\n",
    "# Define the folder structure\n",
    "# directories = [\n",
    "#     \"pos/tempo_70_145/foot\",\"pos/tempo_70_145/hand\",\"pos/tempo_70_145/score/foot\",\"pos/tempo_70_145/score/hand\",\n",
    "#     \"vel/tempo_70_145/foot\",\"vel/tempo_70_145/hand\",\"vel/tempo_70_145/score/foot\",\"vel/tempo_70_145/score/hand\",\n",
    "#     \"stats_pos/tempo_70_145/uni\",\"stats_pos/tempo_70_145/bi\",\n",
    "#     \"stats_vel/tempo_70_145/uni\",\"stats_vel/tempo_70_145/bi\",\n",
    "#     \"stats_posvel/tempo_70_145/uni\",\"stats_posvel/tempo_70_145/bi\"\n",
    "# ]\n",
    "\n",
    "# for dir_path in directories:\n",
    "#     full_path = os.path.join(main_dir, dir_path)\n",
    "#     os.makedirs(full_path, exist_ok=True)\n",
    "# print(\"All directories and subdirectories have been created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Window Size parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_dict = {9: \"left_wrist\", 10: \"right_wrist\", \n",
    "                15: \"left_ankle\", 16: \"right_ankle\", \n",
    "                }   # 11: \"left_hip\",12: \"right_hip\"\n",
    "\n",
    "# config1 = {\"sub_dir\": [\"hand\"], \"mode\": [\"zero_uni\", \"zero_bi\"], \"markerA_id\": [9, 10], \"a\": 70, \"b\": 145}\n",
    "# config2 = {\"sub_dir\": [\"foot\"], \"mode\": [\"zero_uni\", \"zero_bi\"], \"markerA_id\": [15, 16], \"a\": 70, \"b\": 145}\n",
    "# config3 = {\"sub_dir\": [\"hand\"], \"mode\": [\"zero_uni\", \"zero_bi\"], \"markerA_id\": [9, 10], \"a\": 60, \"b\": 180}\n",
    "# config4 = {\"sub_dir\": [\"foot\"], \"mode\": [\"zero_uni\", \"zero_bi\"], \"markerA_id\": [15, 16], \"a\": 60, \"b\": 180}\n",
    "\n",
    "config1 = {\"sub_dir\": [\"hand\"], \"mode\": [\"zero_uni\", \"zero_bi\"], \"markerA_id\": [9, 10], \"a\": 70, \"b\": 145,\n",
    "           \"win_size_list\": np.arange(1,14).tolist()}      # 4 beat window\n",
    "\n",
    "config2 = {\"sub_dir\": [\"foot\"], \"mode\": [\"zero_uni\", \"zero_bi\"], \"markerA_id\": [15, 16], \"a\": 70, \"b\": 145,\n",
    "           \"win_size_list\": np.arange(1,14).tolist()}      # 4 beat window\n",
    "\n",
    "\n",
    "\n",
    "case = \"win_case_2\"\n",
    "configs = [config1, config2]\n",
    "\n",
    "total_iterations = sum(\n",
    "    len(cfg[\"sub_dir\"]) * len(cfg[\"mode\"]) * len(cfg[\"markerA_id\"]) * len(cfg[\"win_size_list\"]) * 4\n",
    "    for cfg in configs\n",
    ")\n",
    "\n",
    "with tqdm(total=total_iterations, desc=\"Processing Configurations\") as pbar:\n",
    "    for cfg in configs:\n",
    "        a = cfg[\"a\"]\n",
    "        b = cfg[\"b\"]\n",
    "        for sub_dir in cfg[\"sub_dir\"]:\n",
    "            for mode in cfg[\"mode\"]:\n",
    "                for markerA_id in cfg[\"markerA_id\"]:\n",
    "                    for w_sec in cfg['win_size_list']:\n",
    "                        for h_sec in [w_sec*0.25, w_sec*0.5, w_sec*0.75, w_sec*1]:\n",
    "                            # h_sec = w_sec/4\n",
    "                            # savepath = f\"./saved_results/{case}/tempo_{a}_{b}\"\n",
    "                            csv_dir = f\"./saved_results/{case}/vel/tempo_{a}_{b}/{sub_dir}\"\n",
    "                            csv_filename = f\"{marker_dict[markerA_id]}_W{w_sec}H{h_sec}_{mode}_{a}_{b}.csv\"\n",
    "                            csv_file_path = os.path.join(csv_dir, csv_filename)\n",
    "                            \n",
    "                            aist_pos1s(a, b, mode, markerA_id, csv_file_path, w_sec, h_sec, vel_mode= \"on\")\n",
    "                            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tempo Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(tempo_dir):\n",
    "    \n",
    "    main_dir = \"/itf-fi-ml/home/sagardu/aist_tempo_est/optimization/saved_results/tempo_cases\"\n",
    "    \n",
    "    directories = [\n",
    "        f\"{tempo_dir}/pos/foot\", f\"{tempo_dir}/pos/hand\", f\"{tempo_dir}/pos/score/foot\", f\"{tempo_dir}/pos/score/hand\",\n",
    "        f\"{tempo_dir}/vel/foot\", f\"{tempo_dir}/vel/hand\", f\"{tempo_dir}/vel/score/foot\", f\"{tempo_dir}/vel/score/hand\",\n",
    "        f\"{tempo_dir}/stats_pos/uni\", f\"{tempo_dir}/stats_pos/bi\",\n",
    "        f\"{tempo_dir}/stats_vel/uni\", f\"{tempo_dir}/stats_vel/bi\",\n",
    "        f\"{tempo_dir}/stats_posvel/uni\", f\"{tempo_dir}/stats_posvel/bi\"\n",
    "    ]\n",
    "    \n",
    "    for dir_path in directories:\n",
    "        full_path = os.path.join(main_dir, dir_path)\n",
    "        os.makedirs(full_path, exist_ok=True)\n",
    "    # print(f\"Subdirectories created inside {tempo_dir}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "marker_dict = {9: \"left_wrist\", 10: \"right_wrist\", \n",
    "                15: \"left_ankle\", 16: \"right_ankle\", \n",
    "                }   # 11: \"left_hip\",12: \"right_hip\"\n",
    "\n",
    "config1 = {\"sub_dir\": [\"hand\"], \"mode\": [\"zero_uni\", \"zero_bi\"], \"markerA_id\": [9, 10], \n",
    "           \"a\": 60, \n",
    "           \"b\": [100,110,120,130,140,150,160,170,180,190,200],\n",
    "           \"win_size\": 5}      # 4 beat window\n",
    "\n",
    "config2 = {\"sub_dir\": [\"foot\"], \"mode\": [\"zero_uni\", \"zero_bi\"], \"markerA_id\": [15, 16], \n",
    "           \"a\": 60, \n",
    "           \"b\": [100,110,120,130,140,150,160,170,180,190,200],\n",
    "           \"win_size\": 5}      # 4 beat window\n",
    "\n",
    "\n",
    "metric = \"vel\"\n",
    "case = \"tempo_cases\"\n",
    "configs = [config1, config2]\n",
    "\n",
    "total_iterations = 0\n",
    "for cfg in configs:\n",
    "    total_iterations += len(cfg[\"sub_dir\"]) * len(cfg[\"mode\"]) * len(cfg[\"markerA_id\"]) * len(cfg[\"b\"])\n",
    "\n",
    "with tqdm(total=total_iterations, desc=\"Overall progress\") as pbar:\n",
    "    for cfg in configs:\n",
    "        a = cfg[\"a\"]\n",
    "        b = cfg[\"b\"]\n",
    "        w_sec = cfg[\"win_size\"]\n",
    "        h_sec = w_sec/2\n",
    "        \n",
    "        for b in cfg['b']:\n",
    "            create_dir(f\"tempo_{a}_{b}\")\n",
    "            for sub_dir in cfg[\"sub_dir\"]:\n",
    "                for mode in cfg[\"mode\"]:\n",
    "                    for markerA_id in cfg[\"markerA_id\"]:\n",
    "\n",
    "                        csv_dir = f\"./saved_results/{case}/tempo_{a}_{b}/{metric}/{sub_dir}\"\n",
    "                        csv_filename = f\"{marker_dict[markerA_id]}_W{w_sec}H{h_sec}_{mode}_{a}_{b}.csv\"\n",
    "                        csv_file_path = os.path.join(csv_dir, csv_filename)\n",
    "                        \n",
    "                        aist_pos1s(a, b, mode, markerA_id, csv_file_path, w_sec, h_sec, vel_mode= \"on\")\n",
    "                        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = \"../aist_dataset/aist_annotation/keypoints2d\"\n",
    "aist_filelist = os.listdir(f_path)\n",
    "\n",
    "\n",
    "duration_list = []\n",
    "for idx, filename in enumerate(tqdm(aist_filelist)):\n",
    "    \n",
    "    file_path = os.path.join(f_path, filename)\n",
    "    with open(file_path, 'rb') as file:\n",
    "            motion_data = pickle.load(file)\n",
    "\n",
    "    markerA_x = motion_data[\"keypoints2d\"][0, :, 9, 0]\n",
    "    duration = int(len(markerA_x)/60)\n",
    "    duration_list.append(duration)\n",
    "\n",
    "print(\"min:\", min(duration_list))\n",
    "print(\"max:\", max(duration_list))\n",
    "\n",
    "duration_arr = np.array(duration_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(duration_arr[duration_arr<13], bins=10)\n",
    "print(duration_arr[duration_arr<13].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skipped Files Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Skipped_files = ['gPO_sMM_cAll_d12_mPO2_ch07.pkl', 'gBR_sBM_cAll_d04_mBR2_ch05.pkl', 'gJS_sFM_cAll_d03_mJS1_ch02.pkl', 'gMH_sMM_cAll_d24_mMH3_ch10.pkl', 'gLH_sMM_cAll_d18_mLH5_ch10.pkl', 'gJS_sMM_cAll_d02_mJS3_ch03.pkl', 'gBR_sBM_cAll_d05_mBR1_ch10.pkl', 'gPO_sMM_cAll_d11_mPO2_ch04.pkl', 'gBR_sFM_cAll_d06_mBR5_ch21.pkl', 'gJB_sMM_cAll_d09_mJB5_ch10.pkl', 'gLO_sMM_cAll_d15_mLO4_ch09.pkl', 'gBR_sMM_cAll_d06_mBR1_ch07.pkl', 'gHO_sMM_cAll_d19_mHO2_ch02.pkl', 'gBR_sBM_cAll_d04_mBR3_ch08.pkl', 'gLO_sMM_cAll_d14_mLO5_ch06.pkl', 'gJS_sFM_cAll_d03_mJS5_ch13.pkl', 'gJS_sMM_cAll_d01_mJS3_ch03.pkl', 'gLH_sMM_cAll_d17_mLH3_ch05.pkl', 'gWA_sMM_cAll_d27_mWA0_ch07.pkl', 'gKR_sMM_cAll_d30_mKR1_ch08.pkl', 'gHO_sFM_cAll_d20_mHO1_ch09.pkl', 'gBR_sBM_cAll_d05_mBR4_ch07.pkl', 'gHO_sMM_cAll_d21_mHO5_ch10.pkl', 'gBR_sBM_cAll_d04_mBR1_ch07.pkl', 'gWA_sMM_cAll_d25_mWA4_ch02.pkl', 'gLH_sMM_cAll_d17_mLH5_ch06.pkl', 'gJS_sFM_cAll_d02_mJS1_ch02.pkl', 'gPO_sMM_cAll_d11_mPO3_ch05.pkl', 'gBR_sMM_cAll_d05_mBR2_ch05.pkl', 'gMH_sMM_cAll_d23_mMH2_ch06.pkl', 'gBR_sBM_cAll_d05_mBR1_ch08.pkl', 'gBR_sBM_cAll_d05_mBR1_ch07.pkl', 'gJB_sMM_cAll_d07_mJB4_ch02.pkl', 'gBR_sBM_cAll_d06_mBR3_ch07.pkl', 'gBR_sMM_cAll_d06_mBR3_ch08.pkl', 'gBR_sBM_cAll_d05_mBR0_ch10.pkl', 'gBR_sMM_cAll_d06_mBR4_ch09.pkl', 'gJB_sMM_cAll_d07_mJB5_ch03.pkl', 'gJS_sFM_cAll_d02_mJS1_ch11.pkl', 'gLH_sMM_cAll_d16_mLH0_ch01.pkl', 'gLO_sMM_cAll_d13_mLO1_ch02.pkl', 'gJS_sFM_cAll_d01_mJS1_ch02.pkl', 'gMH_sMM_cAll_d24_mMH1_ch08.pkl', 'gBR_sBM_cAll_d04_mBR2_ch10.pkl', 'gPO_sMM_cAll_d10_mPO3_ch02.pkl', 'gKR_sFM_cAll_d30_mKR0_ch15.pkl', 'gMH_sMM_cAll_d22_mMH1_ch02.pkl', 'gBR_sMM_cAll_d05_mBR1_ch04.pkl', 'gMH_sMM_cAll_d23_mMH1_ch05.pkl', 'gBR_sBM_cAll_d05_mBR0_ch07.pkl', 'gKR_sFM_cAll_d29_mKR5_ch13.pkl', 'gJB_sMM_cAll_d07_mJB3_ch01.pkl', 'gBR_sBM_cAll_d04_mBR0_ch10.pkl', 'gJS_sFM_cAll_d02_mJS5_ch10.pkl', 'gLO_sMM_cAll_d14_mLO4_ch05.pkl', 'gJS_sFM_cAll_d03_mJS4_ch12.pkl', 'gLH_sMM_cAll_d17_mLH0_ch04.pkl', 'gLH_sMM_cAll_d16_mLH3_ch03.pkl', 'gKR_sMM_cAll_d29_mKR0_ch04.pkl', 'gJS_sFM_cAll_d01_mJS0_ch01.pkl', 'gHO_sMM_cAll_d20_mHO2_ch04.pkl', 'gLO_sMM_cAll_d13_mLO5_ch03.pkl', 'gBR_sFM_cAll_d04_mBR5_ch06.pkl', 'gKR_sMM_cAll_d30_mKR2_ch09.pkl', 'gKR_sMM_cAll_d28_mKR2_ch03.pkl', 'gHO_sMM_cAll_d20_mHO4_ch06.pkl', 'gBR_sMM_cAll_d04_mBR4_ch02.pkl', 'gBR_sBM_cAll_d05_mBR1_ch09.pkl', 'gBR_sFM_cAll_d04_mBR4_ch05.pkl', 'gHO_sMM_cAll_d19_mHO3_ch03.pkl', 'gBR_sBM_cAll_d04_mBR3_ch05.pkl', 'gBR_sBM_cAll_d06_mBR5_ch08.pkl', 'gBR_sMM_cAll_d04_mBR5_ch03.pkl', 'gBR_sFM_cAll_d06_mBR2_ch16.pkl', 'gBR_sBM_cAll_d04_mBR3_ch07.pkl', 'gLH_sMM_cAll_d18_mLH1_ch07.pkl', 'gBR_sBM_cAll_d06_mBR5_ch05.pkl', 'gHO_sFM_cAll_d19_mHO3_ch04.pkl', 'gBR_sMM_cAll_d06_mBR5_ch10.pkl', 'gJS_sMM_cAll_d02_mJS0_ch04.pkl', 'gMH_sMM_cAll_d24_mMH2_ch09.pkl', 'gHO_sMM_cAll_d20_mHO3_ch05.pkl', 'gJS_sMM_cAll_d02_mJS1_ch02.pkl', 'gPO_sMM_cAll_d12_mPO3_ch08.pkl', 'gJS_sMM_cAll_d03_mJS5_ch05.pkl', 'gBR_sBM_cAll_d06_mBR2_ch10.pkl', 'gBR_sMM_cAll_d04_mBR3_ch01.pkl', 'gJB_sFM_cAll_d08_mJB0_ch08.pkl', 'gPO_sMM_cAll_d12_mPO5_ch09.pkl', 'gJB_sMM_cAll_d09_mJB1_ch08.pkl', 'gBR_sBM_cAll_d06_mBR3_ch08.pkl', 'gMH_sFM_cAll_d22_mMH1_ch02.pkl', 'gHO_sFM_cAll_d20_mHO0_ch08.pkl', 'gBR_sBM_cAll_d05_mBR0_ch08.pkl', 'gWA_sMM_cAll_d25_mWA5_ch03.pkl', 'gBR_sFM_cAll_d04_mBR1_ch02.pkl', 'gKR_sMM_cAll_d29_mKR5_ch06.pkl', 'gJS_sMM_cAll_d03_mJS0_ch01.pkl', 'gWA_sMM_cAll_d26_mWA5_ch06.pkl', 'gJB_sFM_cAll_d07_mJB3_ch07.pkl', 'gLO_sMM_cAll_d15_mLO5_ch10.pkl', 'gLH_sMM_cAll_d18_mLH3_ch09.pkl', 'gWA_sMM_cAll_d26_mWA3_ch05.pkl', 'gBR_sFM_cAll_d04_mBR4_ch07.pkl', 'gJB_sMM_cAll_d09_mJB0_ch07.pkl', 'gBR_sBM_cAll_d05_mBR5_ch08.pkl', 'gLO_sMM_cAll_d13_mLO0_ch01.pkl', 'gLO_sMM_cAll_d15_mLO0_ch07.pkl', 'gBR_sBM_cAll_d04_mBR0_ch08.pkl', 'gPO_sMM_cAll_d10_mPO5_ch03.pkl', 'gMH_sMM_cAll_d23_mMH0_ch04.pkl', 'gJS_sMM_cAll_d03_mJS1_ch02.pkl', 'gBR_sBM_cAll_d05_mBR5_ch10.pkl', 'gBR_sBM_cAll_d04_mBR3_ch10.pkl', 'gBR_sFM_cAll_d05_mBR4_ch11.pkl', 'gLH_sMM_cAll_d18_mLH2_ch08.pkl', 'gJS_sFM_cAll_d01_mJS3_ch04.pkl', 'gWA_sMM_cAll_d27_mWA2_ch08.pkl', 'gBR_sBM_cAll_d06_mBR4_ch08.pkl', 'gJS_sFM_cAll_d01_mJS1_ch07.pkl', 'gJB_sFM_cAll_d07_mJB2_ch03.pkl', 'gKR_sMM_cAll_d28_mKR1_ch02.pkl', 'gBR_sBM_cAll_d04_mBR1_ch10.pkl', 'gHO_sFM_cAll_d20_mHO5_ch13.pkl', 'gLO_sMM_cAll_d14_mLO1_ch04.pkl', 'gJB_sFM_cAll_d09_mJB1_ch16.pkl', 'gMH_sMM_cAll_d22_mMH2_ch03.pkl', 'gBR_sFM_cAll_d04_mBR3_ch04.pkl', 'gBR_sFM_cAll_d05_mBR5_ch14.pkl', 'gPO_sMM_cAll_d12_mPO4_ch10.pkl', 'gHO_sMM_cAll_d19_mHO0_ch01.pkl', 'gWA_sMM_cAll_d25_mWA1_ch01.pkl', 'gKR_sFM_cAll_d28_mKR5_ch06.pkl', 'gKR_sMM_cAll_d29_mKR1_ch05.pkl', 'gKR_sFM_cAll_d28_mKR3_ch07.pkl', 'gKR_sMM_cAll_d28_mKR0_ch01.pkl', 'gMH_sMM_cAll_d22_mMH0_ch01.pkl', 'gHO_sMM_cAll_d21_mHO2_ch07.pkl', 'gPO_sMM_cAll_d11_mPO5_ch06.pkl', 'gJS_sFM_cAll_d02_mJS3_ch04.pkl', 'gBR_sBM_cAll_d05_mBR4_ch10.pkl', 'gBR_sMM_cAll_d05_mBR4_ch06.pkl', 'gHO_sMM_cAll_d21_mHO4_ch09.pkl', 'gHO_sFM_cAll_d20_mHO3_ch14.pkl', 'gKR_sMM_cAll_d30_mKR0_ch07.pkl', 'gWA_sMM_cAll_d27_mWA5_ch10.pkl', 'gJS_sMM_cAll_d01_mJS1_ch02.pkl', 'gBR_sBM_cAll_d04_mBR2_ch08.pkl', 'gJS_sFM_cAll_d02_mJS0_ch08.pkl', 'gJS_sMM_cAll_d01_mJS0_ch01.pkl', 'gWA_sMM_cAll_d27_mWA3_ch09.pkl', 'gLH_sMM_cAll_d16_mLH2_ch02.pkl', 'gPO_sMM_cAll_d10_mPO2_ch01.pkl', 'gJB_sFM_cAll_d09_mJB2_ch17.pkl', 'gBR_sBM_cAll_d04_mBR1_ch08.pkl', 'gLO_sMM_cAll_d15_mLO1_ch08.pkl', 'gJS_sMM_cAll_d03_mJS3_ch03.pkl', 'gWA_sMM_cAll_d26_mWA2_ch04.pkl', 'gBR_sFM_cAll_d04_mBR2_ch03.pkl', 'gBR_sBM_cAll_d05_mBR5_ch07.pkl', 'gJB_sMM_cAll_d08_mJB3_ch05.pkl', 'gJB_sMM_cAll_d09_mJB3_ch09.pkl', 'gHO_sMM_cAll_d21_mHO3_ch08.pkl', 'gBR_sBM_cAll_d05_mBR4_ch08.pkl', 'gMH_sMM_cAll_d24_mMH0_ch07.pkl', 'gBR_sFM_cAll_d05_mBR2_ch09.pkl', 'gJB_sMM_cAll_d08_mJB1_ch04.pkl', 'gJB_sMM_cAll_d08_mJB4_ch06.pkl', 'gKR_sMM_cAll_d30_mKR3_ch10.pkl']\n",
    "\n",
    "f_path = \"./aist_dataset/aist_annotation/keypoints2d\"\t\n",
    "\n",
    "for idx, filename in enumerate(tqdm(Skipped_files)):\n",
    "        \n",
    "    file_path = os.path.join(f_path, filename)\n",
    "    with open(file_path, 'rb') as file:\n",
    "            motion_data = pickle.load(file)\n",
    "\n",
    "    markerA_x = motion_data[\"keypoints2d\"][0, :, markerA_id, 0]     # array (n,)\n",
    "    markerA_y = motion_data[\"keypoints2d\"][0, :, markerA_id, 1]      # array (n,)\n",
    "    \n",
    "    print(len(markerA_x))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"filename\": [],\n",
    "    \"dance_genre\": [],\n",
    "    \"situation\": [],\n",
    "    \"camera_id\": [],\n",
    "    \"dancer_id\": [],\n",
    "    \"music_id\": [],\n",
    "    \"choreo_id\": [],\n",
    "    \"music_tempo\": [],\n",
    "\n",
    "    \"X_a\": [],\n",
    "    \"Y_a\": [],\n",
    "\n",
    "    \"bpm_mode\": [],\n",
    "    \"bpm_median\": [],\n",
    "    \"mode_x\": [],\n",
    "    \"mode_y\": [],\n",
    "\n",
    "    \"median_x\": [],\n",
    "    \"median_y\": [],\n",
    "\n",
    "}\n",
    "\n",
    "json_filename = \"music_id_tempo.json\"\n",
    "with open(json_filename, \"r\") as file:\n",
    "    aist_tempo = json.load(file)\n",
    "\n",
    "f_path = \"./aist_dataset/aist_annotation/keypoints2d\"\n",
    "aist_filelist = os.listdir(f_path)\n",
    "\n",
    "mocap_fps = 60\n",
    "a = 70; b =145\n",
    "tempi_range = np.arange(a,b,1)   # good: 70,145 \n",
    "\n",
    "marker_dict = {9: \"left_wrist\", 10: \"right_wrist\", \n",
    "               15: \"left_ankle\", 16: \"right_ankle\", \n",
    "               11: \"left_hip\",12: \"right_hip\"}\n",
    "\n",
    "\n",
    "sub_dir = \"foot\"\n",
    "mode = \"zero_bi\"\n",
    "markerA_id = 16          # 9: \"left_wrist\", 10: \"right_wrist\", 15: \"left_ankle\", 16: \"right_ankle\"\n",
    "csv_filename = f\"./results/aist_pos1s/z-score/tempo_{a}_{b}/{sub_dir}/{marker_dict[markerA_id]}_{mode}_{a}_{b}.csv\"        \n",
    "\n",
    "for idx, filename in enumerate(tqdm(aist_filelist)):\n",
    "    \n",
    "    file_path = os.path.join(f_path, filename)\n",
    "    file_info = filename.split(\"_\")\n",
    "    dance_genre = file_info[0] \n",
    "    situation = file_info[1] \n",
    "    camera_id = file_info[2] \n",
    "    dancer_id = file_info[3]\n",
    "    music_id = file_info[4]\n",
    "    choreo_id = file_info[5].strip(\".pkl\")\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        motion_data = pickle.load(file)\n",
    "\n",
    "    markerA_x = motion_data[\"keypoints2d\"][0, :, markerA_id, 0]     # array (n,)\n",
    "    markerA_y = motion_data[\"keypoints2d\"][0, :, markerA_id, 1]      # array (n,)\n",
    "    \n",
    "    \n",
    "\n",
    "    if np.all((markerA_x == 0) & (markerA_y == 0)) or np.any(np.isnan(markerA_x) | np.isnan(markerA_y)):\n",
    "        continue\n",
    "    \n",
    "    markerA_x = detrend_signal_array(markerA_x.reshape(-1, 1), cutoff= 1, fs=60)\n",
    "    markerA_y = detrend_signal_array(markerA_y.reshape(-1, 1), cutoff= 1, fs=60)\n",
    "    markerA_pos = np.concatenate((markerA_x, markerA_y), axis=1)  # size (n,2)\n",
    "    \n",
    "    duration = int(len(markerA_x)/60)\n",
    "    w_sec = int(duration)\n",
    "    h_sec = int(w_sec/4)\n",
    "    window_size = int(mocap_fps*w_sec)\n",
    "    hop_size = int(mocap_fps*h_sec)\n",
    "    \n",
    "    bpm_axes = []\n",
    "    for ax in range(2):\n",
    "        # min max -1 to 1\n",
    "        # x_min, x_max = np.min(markerA_pos[:, ax]), np.max(markerA_pos[:, ax])\n",
    "        # markerA_pos_norm = (\n",
    "        #     2 * (markerA_pos[:, ax] - x_min) / (x_max - x_min) - 1\n",
    "        #     if x_max != x_min  # Avoid division by zero\n",
    "        #     else np.zeros_like(markerA_pos[:, ax])\n",
    "        # )\n",
    "        \n",
    "        # z-score\n",
    "        mean_x = np.mean(markerA_pos[:, ax])\n",
    "        std_x = np.std(markerA_pos[:, ax])\n",
    "        \n",
    "        markerA_pos_norm = (\n",
    "        (markerA_pos[:, ax] - mean_x) / std_x if std_x != 0 else np.zeros_like(markerA_pos[:, ax])\n",
    "        )\n",
    "\n",
    "        markerA_ax = markerA_pos_norm.reshape(-1,1)\n",
    "              \n",
    "        tempo_json_one_sensor = main_one_sensor_peraxis(markerA_ax,\n",
    "                                                        mocap_fps, window_size, hop_size, tempi_range, \n",
    "                                                        T_filter=0.25, smooth_wlen= 10, pk_order = 15 ,mode= mode)\n",
    "\n",
    "        \n",
    "        sensor_onsets = tempo_json_one_sensor[\"sensor_onsets\"]\n",
    "        tempo_data_maxmethod = tempo_json_one_sensor[\"tempo_data_maxmethod\"]\n",
    "        bpmA_arr = tempo_data_maxmethod[\"bpm_arr\"]      # bpm per window\n",
    "        tempo_A = np.round(np.average(bpmA_arr), 2)\n",
    "        bpm_axes.append(bpmA_arr)\n",
    "        \n",
    "        mode_ax = stats.mode(bpmA_arr.flatten())[0]\n",
    "        median_ax = np.median(bpmA_arr.flatten())\n",
    "\n",
    "        if ax == 0:\n",
    "            result[\"filename\"].append(filename.strip(\".pkl\"))\n",
    "            result[\"dance_genre\"].append(dance_genre)\n",
    "            result[\"situation\"].append(situation)\n",
    "            result[\"camera_id\"].append(camera_id)\n",
    "            result[\"dancer_id\"].append(dancer_id)\n",
    "            result[\"music_id\"].append(music_id)\n",
    "            result[\"choreo_id\"].append(choreo_id)\n",
    "            result[\"music_tempo\"].append(aist_tempo[music_id])\n",
    "            \n",
    "            result[\"mode_x\"].append(mode_ax)\n",
    "            result[\"median_x\"].append(median_ax)\n",
    "            result[\"X_a\"].append(tempo_A)\n",
    "            \n",
    "        elif ax == 1:\n",
    "            result[\"mode_y\"].append(mode_ax)\n",
    "            result[\"median_y\"].append(median_ax)\n",
    "            result[\"Y_a\"].append(tempo_A)\n",
    "\n",
    "    bpm_axes_arr = np.column_stack(bpm_axes)    # n by 3 array\n",
    "    bpm_mode = stats.mode(bpm_axes_arr.flatten())[0]\n",
    "    bpm_median = np.median(bpm_axes_arr.flatten())\n",
    "    result[\"bpm_mode\"].append(bpm_mode)\n",
    "    result[\"bpm_median\"].append(bpm_median)    \n",
    "    \n",
    "    \n",
    "# results_df = pd.DataFrame(result)\n",
    "# results_df.to_csv(csv_filename, index=False)\n",
    "# print(f\"Results saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(markerA_ax.shape)\n",
    "print(sensor_onsets.shape)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract x and y positions for the given keypoint\n",
    "markerA_x = motion_data[\"keypoints2d\"][0, :, 10, 0]\n",
    "markerA_y = motion_data[\"keypoints2d\"][0, :, 10, 1]\n",
    "\n",
    "# Normalize x and y to [0,1] range\n",
    "x_min, x_max = np.min(markerA_x), np.max(markerA_x)\n",
    "y_min, y_max = np.min(markerA_y), np.max(markerA_y)\n",
    "\n",
    "x_norm = (markerA_x - x_min) / (x_max - x_min) if x_max != x_min else np.zeros_like(markerA_x)\n",
    "y_norm = (markerA_y - y_min) / (y_max - y_min) if y_max != y_min else np.zeros_like(markerA_y)\n",
    "\n",
    "# Smooth the normalized position data\n",
    "xs = smooth_velocity(x_norm.reshape(-1, 1), abs=\"no\", window_length=10, polyorder=0)\n",
    "ys = smooth_velocity(y_norm.reshape(-1, 1), abs=\"no\", window_length=10, polyorder=0)\n",
    "\n",
    "\n",
    "# Plot position and velocity\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), dpi=100)\n",
    "fig.suptitle('Position and Velocity')\n",
    "\n",
    "# Position plots\n",
    "axs[0].plot(xs, label=\"x position\")\n",
    "axs[1].plot(ys, label=\"y position\")\n",
    "axs[0].set_title(\"X Position\")\n",
    "axs[1].set_title(\"Y Position\")\n",
    "\n",
    "# Formatting\n",
    "for ax in axs.flat:\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aist_pos1s_script import load_from_json\n",
    "a = 70\n",
    "b = 145\n",
    "\n",
    "savepath = f\"./results/aist_pos1s/z-score/tempo_{a}_{b}/tempo_data/json/ax0\"\n",
    "\n",
    "right_ankle_json = load_from_json(savepath, \"right_ankle_gLO_sBM_cAll_d15_mLO5_ch06_axis0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_ankle_json.keys()\n",
    "right_ankle_json['tempo_data_maxmethod'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(right_ankle_json['sensor_abs'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
