{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# from dance_evaluation import *\n",
    "import matplotlib.pyplot as plt\n",
    "# from calculate_score import *\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_pickle(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        json_data = pickle.load(f)\n",
    "    return json_data\n",
    "\n",
    "def save_to_pickle(filepath, data):\n",
    "    # filepath = os.path.join(savepath, filename)\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dance Tempo Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dts(\n",
    "    ref_bpm,\n",
    "    estimated_bpm,\n",
    "    tau=0.1,\n",
    "    mode=\"one\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Continuous Dance-Tempo Score (DTS), with support for\n",
    "    either single estimates (mode=\"one\") or multiple\n",
    "    candidates per frame (mode=\"many\").\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ref_bpm : array-like, shape (n,)\n",
    "        Ground-truth musical tempo in BPM.\n",
    "    estimated_bpm : \n",
    "        If mode=\"one\": array-like, shape (n,)\n",
    "        If mode=\"many\": iterable of length-n, each element\n",
    "                        is an iterable of candidate BPMs.\n",
    "    tau : float, optional\n",
    "        Tolerance in octaves (0.06 ≈ 4 %).\n",
    "    mode : {\"one\", \"many\"} \n",
    "        “one”: treat `estimated_bpm` as a flat sequence.\n",
    "        “many”: pick, for each i, the candidate closest to ref_bpm[i]. For best of two\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dts : ndarray, shape (n,)\n",
    "        Scores in [0, 1] (1 = perfect, 0 = miss ≥ τ octaves away).\n",
    "    e : ndarray, shape (n,)\n",
    "        Raw octave errors log₂(estimate/ref).\n",
    "    d : ndarray, shape (n,)\n",
    "        Wrapped distance to {-1, 0, +1} before clipping.\n",
    "    \"\"\"\n",
    "    ref_bpm = np.asarray(ref_bpm, dtype=float)\n",
    "\n",
    "    # select a single estimate per index if needed\n",
    "    if mode == \"many\":\n",
    "        chosen = np.array([\n",
    "            min(cands, key=lambda b: abs(b - ref_bpm[i]))\n",
    "            for i, cands in enumerate(estimated_bpm)\n",
    "        ], dtype=float)\n",
    "    elif mode == \"one\":\n",
    "        chosen = np.asarray(estimated_bpm, dtype=float)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode!r}. Use 'one' or 'many'.\")\n",
    "\n",
    "    # DTS core ------------------------------------------------------\n",
    "    e = np.log2(chosen / ref_bpm)\n",
    "    # distance from nearest of -1, 0, +1\n",
    "    d = np.abs(e[:, None] - np.array([-1.0, 0.0, 1.0])).min(axis=1)\n",
    "    # clip by tolerance and convert to score\n",
    "    d_clip = np.minimum(d, tau)\n",
    "    dts    = 1.0 - d_clip / tau\n",
    "\n",
    "    accuracy = (dts > 0.0).mean() * 100\n",
    "    \n",
    "    # hits ----------------------------------------------------------\n",
    "    hit_mask = dts > 0.0          # inside ±tau band\n",
    "    hit_idx = np.nonzero(hit_mask)[0]\n",
    "    ref_hit_bpm = ref_bpm[hit_idx]\n",
    "    \n",
    "    return dts, e, d, accuracy, hit_idx, ref_hit_bpm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendly = {\n",
    "    \"adaptv_Bhandfoot_y\":  \"Both-Hand + Foot (Y)\",\n",
    "    \"adaptv_LRfoot_xy\":    \"L-/R-Foot (XY)\",\n",
    "    \"adaptv_LRfoot_res\":   \"L-/R-Foot (Resultant)\",\n",
    "    \"adaptv_LRhand_xy\":    \"L-/R-Hand (XY)\",\n",
    "    \"adaptv_LRhand_res\":   \"L-/R-Hand (Resultant)\",\n",
    "    \"adaptv_Bfoot_x_y\":    \"Both-Foot (X & Y)\",\n",
    "    \"adaptv_Bhandfoot_x\":  \"Both-Hand & Both-Foot (X)\",\n",
    "    \"adaptv_Bhand_x_y\":    \"Both-Hand (X & Y)\",\n",
    "    \"adaptv_Bhandfoot_res\":\"Both-Hand & Both-Foot (Resultant)\",\n",
    "}\n",
    "\n",
    "def estimate_tempo_posvel(a, b, mode, w_sec, h_sec):\n",
    "    # Using both zero velocity and peak velocity\n",
    "    segment_pairs = [\n",
    "        \"adaptv_Bhandfoot_y\",\n",
    "        \"adaptv_Bhandfoot_x\",\n",
    "        \"adaptv_LRhand_xy\",\n",
    "        \"adaptv_LRfoot_xy\",\n",
    "        \"adaptv_Bhand_x_y\",\n",
    "        \"adaptv_Bfoot_x_y\",\n",
    "        \"adaptv_LRfoot_res\",\n",
    "        \"adaptv_LRhand_res\",\n",
    "        \"adaptv_Bhandfoot_res\",\n",
    "        ]\n",
    "    \n",
    "\n",
    "    \n",
    "    score_data = {}\n",
    "    json_data = {}\n",
    "    # oPath = f\"./saved_result/tttempo_{a}_{b}/\"\n",
    "    root = \"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result_adaptive\"\n",
    "    pth_pos = f\"{root}/tempo_{a}_{b}/pos\"\n",
    "    pth_vel = f\"{root}/tempo_{a}_{b}/vel\"\n",
    "    \n",
    "    pth_rms = f\"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result_rms_adaptive/tempo_{a}_{b}/pos\"\n",
    "    \n",
    "    bpm_dict = [\"bpm_avg\",  \"bpm_mode\", \"bpm_median\"]\n",
    "    for bpm_mode in bpm_dict:\n",
    "        score_data[bpm_mode] = {}\n",
    "        json_data[bpm_mode] = {}\n",
    "        for seg in segment_pairs:\n",
    "            fpath_pos = os.path.join(pth_pos, f\"{seg}_{mode}_W{w_sec}_H{h_sec}_{a}_{b}.pkl\")\n",
    "            fpath_vel = os.path.join(pth_vel, f\"{seg}_{mode}_W{w_sec}_H{h_sec}_{a}_{b}.pkl\")\n",
    "            \n",
    "            fpath_rms = os.path.join(pth_rms, f\"{seg}_{mode}_W{w_sec}_H{h_sec}_{a}_{b}.pkl\") \n",
    "            fpath_torso = os.path.join(\"/itf-fi-ml/home/sagardu/aist_tempo_est/extracted_body_onsets_sept25/torso\", f\"torso_y_zero_uni_W5_H2.5_60_140.pkl\")\n",
    "            \n",
    "            df1 = load_pickle(fpath_pos)\n",
    "            df2 = load_pickle(fpath_vel)\n",
    "            df3 = load_pickle(fpath_rms)   # RMS position\n",
    "            df4 = load_pickle(fpath_torso)   # Torso Y position\n",
    "\n",
    "            # Build candidate BPM pairs \n",
    "            bpm_pos = []\n",
    "            bpm_vel = []\n",
    "            bpm_posvel = []\n",
    "            for n in range(df1.shape[0]):\n",
    "                bpm1 = df1.iloc[n][bpm_mode]   # \n",
    "                bpm2 = df2.iloc[n][bpm_mode]   #  \n",
    "                bpm3 = df3.iloc[n][bpm_mode]   #  RMS position\n",
    "                bpm4 = df4.iloc[n][bpm_mode]   #  torso Y \n",
    "\n",
    "                # bpm_posvel.append((bpm1, bpm2))\n",
    "                bpm_posvel.append((bpm1, bpm2, bpm3, bpm4))\n",
    "            \n",
    "            # music_tempo from df1 \n",
    "            ref = df1[\"music_tempo\"].to_numpy()\n",
    "            \n",
    "            _, _, _, dts_acc3, hit_idx, ref_hit_bpm = compute_dts(ref, bpm_posvel, tau=0.10, mode = \"many\")\n",
    "            \n",
    "            score_data[bpm_mode][friendly[seg]] = {\"acc\": dts_acc3, \"hit_idx\": hit_idx, \"ref_hit_bpm\": ref_hit_bpm}\n",
    "            \n",
    "            json_data[bpm_mode][seg] = {\"bpm_pos\": bpm_pos,\n",
    "                                             \"bpm_vel\": bpm_vel,\n",
    "                                            \"bpm_posvel\": bpm_posvel,\n",
    "                                            \"Acc1_bpm_pos\": 5,\n",
    "                                            \"Acc1_bpm_vel\": 5,\n",
    "                                            \"Acc1_bpm_posvel\": dts_acc3,}\n",
    "            \n",
    "    \n",
    "    #### Sace the score data to a pickle file\n",
    "    # save_dir = f\"./saved_result_rms_adaptive/tempo_{a}_{b}/score\"\n",
    "    # fname1 = f\"score_multi_adap_posvelenergy_{mode}_W{w_sec}_H{h_sec}_{a}_{b}.pkl\"\n",
    "    # fpath1 = os.path.join(save_dir, fname1)\n",
    "    # save_to_pickle(fpath1, score_data)\n",
    "        \n",
    "    return json_data\n",
    "\n",
    "accuracy_dict_posvel = estimate_tempo_posvel(60, 140, \"zero_uni\", 5, 5/2)   # Best of two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Both-Hand + Foot (Y)': 75.17,\n",
       " 'Both-Hand & Both-Foot (X)': 54.29,\n",
       " 'L-/R-Hand (XY)': 70.84,\n",
       " 'L-/R-Foot (XY)': 64.35,\n",
       " 'Both-Hand (X & Y)': 72.48,\n",
       " 'Both-Foot (X & Y)': 67.41,\n",
       " 'L-/R-Foot (Resultant)': 19.39,\n",
       " 'L-/R-Hand (Resultant)': 19.39,\n",
       " 'Both-Hand & Both-Foot (Resultant)': 44.3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_pairs = [\n",
    "        \"adaptv_Bhandfoot_y\",\n",
    "        \"adaptv_Bhandfoot_x\",\n",
    "        \"adaptv_LRhand_xy\",\n",
    "        \"adaptv_LRfoot_xy\",\n",
    "        \"adaptv_Bhand_x_y\",\n",
    "        \"adaptv_Bfoot_x_y\",\n",
    "        \"adaptv_LRfoot_res\",\n",
    "        \"adaptv_LRhand_res\",\n",
    "        \"adaptv_Bhandfoot_res\",\n",
    "        ]\n",
    "friendly = {\n",
    "    \"adaptv_Bhandfoot_y\":  \"Both-Hand + Foot (Y)\",\n",
    "    \"adaptv_LRfoot_xy\":    \"L-/R-Foot (XY)\",\n",
    "    \"adaptv_LRfoot_res\":   \"L-/R-Foot (Resultant)\",\n",
    "    \"adaptv_LRhand_xy\":    \"L-/R-Hand (XY)\",\n",
    "    \"adaptv_LRhand_res\":   \"L-/R-Hand (Resultant)\",\n",
    "    \"adaptv_Bfoot_x_y\":    \"Both-Foot (X & Y)\",\n",
    "    \"adaptv_Bhandfoot_x\":  \"Both-Hand & Both-Foot (X)\",\n",
    "    \"adaptv_Bhand_x_y\":    \"Both-Hand (X & Y)\",\n",
    "    \"adaptv_Bhandfoot_res\":\"Both-Hand & Both-Foot (Resultant)\",\n",
    "}\n",
    "\n",
    "best_of_three={}\n",
    "for seg in segment_pairs:\n",
    "    best_of_three[friendly[seg]] = np.round(accuracy_dict_posvel[\"bpm_median\"][seg][\"Acc1_bpm_posvel\"],2)\n",
    "    \n",
    "best_of_three   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For adaptive weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L-/R-Hand (XY)': 47.13,\n",
       " 'L-/R-Hand (Resultant)': 20.36,\n",
       " 'L-/R-Foot (Resultant)': 20.36,\n",
       " 'Both-Hand + Foot (Y)': 58.99,\n",
       " 'Both-Foot (X & Y)': 44.15,\n",
       " 'Both-Hand (X & Y)': 51.53,\n",
       " 'Both-Hand & Both-Foot (X)': 27.59,\n",
       " 'L-/R-Foot (XY)': 39.67,\n",
       " 'Both-Hand & Both-Foot (Resultant)': 20.36}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# path setup\n",
    "a, b = 60, 140\n",
    "root = \"/itf-fi-ml/home/sagardu/aist_tempo_est/saved_result_rms_adaptive\"\n",
    "pth_pos = f\"{root}/tempo_{a}_{b}/pos\"\n",
    "# pth_vel = f\"{root}/tempo_{a}_{b}/vel\"\n",
    "\n",
    "# descriptive labels for plot axis\n",
    "friendly = {\n",
    "    \"adaptv_Bhandfoot_y\":  \"Both-Hand + Foot (Y)\",\n",
    "    \"adaptv_LRfoot_xy\":    \"L-/R-Foot (XY)\",\n",
    "    \"adaptv_LRfoot_res\":   \"L-/R-Foot (Resultant)\",\n",
    "    \"adaptv_LRhand_xy\":    \"L-/R-Hand (XY)\",\n",
    "    \"adaptv_LRhand_res\":   \"L-/R-Hand (Resultant)\",\n",
    "    \"adaptv_Bfoot_x_y\":    \"Both-Foot (X & Y)\",\n",
    "    \"adaptv_Bhandfoot_x\":  \"Both-Hand & Both-Foot (X)\",\n",
    "    \"adaptv_Bhand_x_y\":    \"Both-Hand (X & Y)\",\n",
    "    \"adaptv_Bhandfoot_res\":\"Both-Hand & Both-Foot (Resultant)\",\n",
    "}\n",
    "\n",
    "# helper to compute accuracy and fill a dictionary\n",
    "def collect_accuracies(folder, metric):\n",
    "    acc = {}\n",
    "    score_data = {\"bpm_median\": {}, \"bpm_avg\": {}, \"bpm_mode\": {}}\n",
    "    for fname in os.listdir(folder):\n",
    "        \n",
    "        if \"zero_bi\" in fname:\n",
    "            continue\n",
    "        \n",
    "        tag = fname.split(\"_zero_uni\")[0]\n",
    "        data = load_pickle(f\"{folder}/{fname}\")\n",
    "        ref  = data[\"music_tempo\"].to_numpy()\n",
    "        _, _, _, accuracy, hit_idx, ref_hit_bpm = compute_dts(ref, data[\"bpm_median\"].to_numpy(),\n",
    "                                            tau=0.10, mode=\"one\")\n",
    "        \n",
    "        acc[friendly[tag]] = round(accuracy, 2)\n",
    "        \n",
    "        score_data[\"bpm_median\"][friendly[tag]] = {\"acc\": accuracy, \"hit_idx\": hit_idx, \"ref_hit_bpm\": ref_hit_bpm}\n",
    "        \n",
    "    # save the score data\n",
    "    # save_dir = f\"./saved_result_adaptive/tempo_{a}_{b}/score\"\n",
    "    # fname1 = f\"score_multi_adap_{metric}_zero_uni_W5_H2.5_25_140.pkl\"\n",
    "    # fpath1 = os.path.join(save_dir, fname1)\n",
    "    # save_to_pickle(fpath1, score_data)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# build two dicts, one for pos and one for vel, ready for bar plotting\n",
    "accuracy_dict_energy = collect_accuracies(pth_pos, \"pos\")\n",
    "# accuracy_dict_vel = collect_accuracies(pth_vel, \"vel\")\n",
    "\n",
    "accuracy_dict_energy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
