{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449606e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.eval import *\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import glob\n",
    "import librosa\n",
    "import moviepy as mp\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import correlate\n",
    "from scipy.signal import find_peaks\n",
    "from madmom.features.beats import RNNBeatProcessor, DBNBeatTrackingProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16c1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 45, 140\n",
    "tau = 0.13\n",
    "\n",
    "accuracy_zero = evaluation_multi_segment(\"anchor_zero\", \"uni\",a,b, tolerance= tau)\n",
    "accuracy_peak= evaluation_multi_segment(\"anchor_peak\", \"uni\",a,b, tolerance= tau)\n",
    "accuracy_energy = evaluation_multi_segment(\"anchor_energy\", \"uni\",a,b, tolerance= tau)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc54dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_zero   = accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni']['hit_idx']\n",
    "hits_peak   = accuracy_peak['bothhand_y_bothfoot_y_torso_y_uni']['hit_idx']\n",
    "hits_energy = accuracy_energy['bothhand_y_bothfoot_y_torso_y_uni']['hit_idx']\n",
    "\n",
    "hits_seg_zero = accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni']['hit_seg_names']\n",
    "hits_seg_peak = accuracy_peak['bothhand_y_bothfoot_y_torso_y_uni']['hit_seg_names']\n",
    "hits_seg_energy = accuracy_energy['bothhand_y_bothfoot_y_torso_y_uni']['hit_seg_names']\n",
    "\n",
    "hits_beat_pulse_zero = accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni']['hit_beat_pulse']\n",
    "hits_beat_pulse_peak = accuracy_peak['bothhand_y_bothfoot_y_torso_y_uni']['hit_beat_pulse']\n",
    "hits_beat_pulse_energy = accuracy_energy['bothhand_y_bothfoot_y_torso_y_uni']['hit_beat_pulse']\n",
    "\n",
    "hits_bpm_zero = accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni']['hit_bpm']\n",
    "hits_bpm_peak = accuracy_peak['bothhand_y_bothfoot_y_torso_y_uni']['hit_bpm']\n",
    "hits_bpm_energy = accuracy_energy['bothhand_y_bothfoot_y_torso_y_uni']['hit_bpm']\n",
    "\n",
    "est_bpm_zero = accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni']['est_bpm']\n",
    "est_bpm_peak = accuracy_peak['bothhand_y_bothfoot_y_torso_y_uni']['est_bpm']\n",
    "est_bpm_energy = accuracy_energy['bothhand_y_bothfoot_y_torso_y_uni']['est_bpm']\n",
    "\n",
    "ref_bpm_zero = accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni']['ref_bpm']\n",
    "ref_bpm_peak = accuracy_peak['bothhand_y_bothfoot_y_torso_y_uni']['ref_bpm']\n",
    "ref_bpm_energy = accuracy_energy['bothhand_y_bothfoot_y_torso_y_uni']['ref_bpm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b7c284b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_bpm_zero[121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6f0258e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133.2 both_hand_y\n",
      "135.0 both_foot_y\n",
      "133.2 both_hand_y\n"
     ]
    }
   ],
   "source": [
    "idx = 124\n",
    "\n",
    "\n",
    "print(est_bpm_zero[idx], hits_seg_zero[idx])\n",
    "print(est_bpm_peak[idx], hits_seg_peak[idx])\n",
    "print(est_bpm_energy[idx], hits_seg_energy[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aist_2d = \"./aist_dataset/video\"\n",
    "filename_zero   = accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni']['filename']\n",
    "filename_peak   = accuracy_peak['bothhand_y_bothfoot_y_torso_y_uni']['filename']\n",
    "filename_energy = accuracy_energy['bothhand_y_bothfoot_y_torso_y_uni']['filename']\n",
    "\n",
    "# Merge & remove duplicates\n",
    "filename_list = np.concatenate((filename_zero,filename_peak,filename_energy), axis=0)\n",
    "filename_list = list(set(filename_list))\n",
    "\n",
    "audio_sr = 22050  # sampling rate for audio\n",
    "motion_sr = 60    # mocap fps\n",
    "\n",
    "cross_modal_results = []\n",
    "completed_files = set()\n",
    "\n",
    "for filename in tqdm(filename_list, total=len(filename_list)):   # ✅ no need enumerate\n",
    "    \n",
    "    # Replace cAll → c01\n",
    "    vid_nm = filename.replace(\"cAll\", \"c01\")\n",
    "    \n",
    "    # Match any channel: c01_dXX_ch*.mp4\n",
    "    search_pattern = os.path.join(aist_2d, vid_nm[:-4] + \"*.mp4\")\n",
    "    candidates = glob.glob(search_pattern)\n",
    "\n",
    "    if filename in completed_files:\n",
    "        continue   # ✅ cleaner\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No matching video found for {vid_nm}\")\n",
    "\n",
    "    vid_path = candidates[0]\n",
    "    video = mp.VideoFileClip(vid_path)\n",
    "\n",
    "    # Build audio output path\n",
    "    audio_path = f\"./aist_dataset/audio/{filename[:-5]}.wav\"\n",
    "\n",
    "    # Avoid re-extracting audio if file already exists\n",
    "    if not os.path.exists(audio_path):\n",
    "        audio = video.audio\n",
    "        audio.write_audiofile(audio_path, fps=audio_sr, logger=None)\n",
    "\n",
    "    completed_files.add(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf2bc8c",
   "metadata": {},
   "source": [
    "## Circular Phase and Anchor Pulse-Beat Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f034075",
   "metadata": {},
   "outputs": [],
   "source": [
    "aist_2d = \"./aist_dataset/video\"\n",
    "hit_beat_pulse = accuracy_peak['bothhand_y_bothfoot_y_torso_y_uni']['hit_beat_pulse']\n",
    "hit_anc_seq = accuracy_peak['bothhand_y_bothfoot_y_torso_y_uni']['hit_anc_seq']\n",
    "filename_list = accuracy_peak['bothhand_y_bothfoot_y_torso_y_uni']['filename']\n",
    "\n",
    "audio_sr = 22050  # sampling rate for audio\n",
    "motion_sr = 60   # your mocap fps\n",
    "\n",
    "cross_modal_results = []\n",
    "\n",
    "for i, filename in tqdm(enumerate(filename_list), total=len(filename_list)):\n",
    "    # vid_nm = filename.replace(\"cAll\", \"c01\")\n",
    "    # search_pattern = os.path.join(aist_2d, vid_nm[:-4] + \"*.mp4\")  # match any chXX\n",
    "    # candidates = glob.glob(search_pattern)\n",
    "    \n",
    "    \n",
    "    # if candidates:\n",
    "    #     vid_path = candidates[0]  # take first match\n",
    "    #     video = mp.VideoFileClip(vid_path)\n",
    "    # else:\n",
    "    #     raise FileNotFoundError(f\"No matching video found for {vid_nm}\")\n",
    "    \n",
    "    \n",
    "    # audio = video.audio\n",
    "    audio_path = f\"./aist_dataset/audio/{filename[:-5]}.wav\"\n",
    "    # audio.write_audiofile(audio_path, fps=audio_sr, logger=None)\n",
    "    \n",
    "    #librrosa beat tracking\n",
    "    # y, sr = librosa.load(audio_path, sr=audio_sr)\n",
    "    # tempo_audio, beats_audio = librosa.beat.beat_track(y=y, sr=sr, units='time')\n",
    "    # beat_pulse_audio = np.zeros(int(y.shape[0] / sr * motion_sr))\n",
    "    # beat_frames_audio = (beats_audio * motion_sr).astype(int)\n",
    "    # beat_pulse_audio[beat_frames_audio[beat_frames_audio < len(beat_pulse_audio)]] = 1\n",
    "    \n",
    "    #madmom beat tracking\n",
    "    proc = DBNBeatTrackingProcessor(fps=100)\n",
    "    act = RNNBeatProcessor()(audio_path)\n",
    "    beats_audio = proc(act)                     # beat times in seconds\n",
    "    tempo_audio = 60.0 / np.median(np.diff(beats_audio))  # BPM\n",
    "    \n",
    "    beat_pulse_audio = np.zeros(int(beats_audio[-1] * motion_sr) + 1)\n",
    "    beat_frames_audio = (beats_audio * motion_sr).astype(int)\n",
    "    beat_pulse_audio[beat_frames_audio] = 1\n",
    "    \n",
    "    \n",
    "    beat_pulse_motion = hit_beat_pulse[i]\n",
    "    # beat_pulse_motion = hit_anc_seq[i]     # anchor sequence\n",
    "    \n",
    "    min_len = min(len(beat_pulse_motion), len(beat_pulse_audio))\n",
    "    beat_pulse_motion = beat_pulse_motion[:min_len]\n",
    "    beat_pulse_audio = beat_pulse_audio[:min_len]\n",
    "    \n",
    "    \n",
    "    corr = correlate(beat_pulse_motion - np.mean(beat_pulse_motion),\n",
    "                     beat_pulse_audio - np.mean(beat_pulse_audio), mode='full')\n",
    "    lag = np.argmax(corr) - (len(beat_pulse_motion) - 1)\n",
    "    max_corr = np.max(corr) / (np.std(beat_pulse_motion) * np.std(beat_pulse_audio) * len(beat_pulse_motion))\n",
    "\n",
    "    # Convert lag to seconds\n",
    "    lag_sec = lag / motion_sr\n",
    "    \n",
    "    \n",
    "    # Find motion beat times from gaussian-like pulse\n",
    "    peaks_motion, _ = find_peaks(beat_pulse_motion, height=np.max(beat_pulse_motion)*0.5, distance=motion_sr*0.3)\n",
    "    beats_motion = peaks_motion / motion_sr  # convert to seconds\n",
    "\n",
    "    \n",
    "    # --- 1. Circular correlation of beat phases ---\n",
    "\n",
    "    circ_corr = np.nan\n",
    "    if len(beats_audio) > 1 and len(beats_motion) > 1:\n",
    "        audio_period = np.median(np.diff(beats_audio))\n",
    "        motion_phase = (2 * np.pi * ((beats_motion % audio_period) / audio_period))\n",
    "        audio_phase  = (2 * np.pi * ((beats_audio % audio_period) / audio_period))\n",
    "        n = min(len(motion_phase), len(audio_phase))\n",
    "        motion_phase, audio_phase = motion_phase[:n], audio_phase[:n]\n",
    "\n",
    "        sin_x = np.sin(motion_phase - np.mean(motion_phase))\n",
    "        sin_y = np.sin(audio_phase - np.mean(audio_phase))\n",
    "        denom = np.sqrt(np.sum(sin_x ** 2) * np.sum(sin_y ** 2))\n",
    "        if denom > 0:\n",
    "            circ_corr = np.sum(sin_x * sin_y) / denom\n",
    "\n",
    "\n",
    "    # --- 2. Coincident-beat fraction (±40 ms tolerance) ---\n",
    "\n",
    "    tol = 0.12  # 40 ms\n",
    "    count_coinc = 0\n",
    "    for t_a in beats_audio:\n",
    "        if np.any(np.abs(t_a - beats_motion) <= tol):\n",
    "            count_coinc += 1\n",
    "    beat_agreement = count_coinc / len(beats_audio) if len(beats_audio) > 0 else np.nan\n",
    "\n",
    "    cross_modal_results.append({\n",
    "        \"filename\": filename,\n",
    "        \"audio_tempo\": tempo_audio,\n",
    "        \"corr_max\": max_corr,\n",
    "        \"lag_sec\": lag_sec,\n",
    "        \"circ_corr\": circ_corr,\n",
    "        \"beat_agreement\": beat_agreement\n",
    "        \n",
    "    })\n",
    "    \n",
    "# save dataframe\n",
    "cross_modal_df = pd.DataFrame(cross_modal_results)\n",
    "cross_modal_df.to_csv(\"./cross_modal_alignment_with_beat_pulse_peak.csv\", index=False)\n",
    "\n",
    "\n",
    "print(cross_modal_df[['corr_max','circ_corr','beat_agreement','lag_sec','audio_tempo']].describe().round(3))\n",
    "\n",
    "# plt.hist(df['corr_max'], bins=20, edgecolor='black')\n",
    "# plt.xlabel('Cross-modal correlation (ρ)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Distribution of Audio–Dance Rhythmic Correlation')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fa9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1448e5a",
   "metadata": {},
   "source": [
    "### Noise Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import moviepy as mp\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "from scipy.signal import correlate\n",
    "from scipy.signal import find_peaks\n",
    "from madmom.features.beats import RNNBeatProcessor, DBNBeatTrackingProcessor\n",
    "\n",
    "aist_2d = \"./aist_dataset/video\"\n",
    "hit_beat_pulse = accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni']['hit_beat_pulse']\n",
    "hit_anc_seq = accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni']['hit_anc_seq']\n",
    "filename_list = accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni']['filename']\n",
    "\n",
    "audio_sr = 22050  # sampling rate for audio\n",
    "motion_sr = 60   # your mocap fps\n",
    "\n",
    "cross_modal_results = []\n",
    "\n",
    "for i, filename in tqdm(enumerate(filename_list), total=len(filename_list)):\n",
    "    vid_nm = filename.replace(\"cAll\", \"c01\")\n",
    "    search_pattern = os.path.join(aist_2d, vid_nm[:-4] + \"*.mp4\")\n",
    "    candidates = glob.glob(search_pattern)\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No matching video found for {vid_nm}\")\n",
    "\n",
    "    vid_path = candidates[0]\n",
    "    video = mp.VideoFileClip(vid_path)\n",
    "\n",
    "    # Save clean audio\n",
    "    audio = video.audio\n",
    "    audio_path = f\"./aist_dataset/audio/temp_audio_{i}.wav\"\n",
    "    audio.write_audiofile(audio_path, fps=audio_sr, logger=None)\n",
    "\n",
    "    # load clean audio\n",
    "    y, sr = librosa.load(audio_path, sr=audio_sr)\n",
    "    snr_list = [20, 10, 5, 0]\n",
    "\n",
    "    for snr in snr_list:\n",
    "\n",
    "        # 1) Inject noise ----------------------------------------\n",
    "        noise = np.random.randn(len(y))\n",
    "        noise = noise / np.max(np.abs(noise))\n",
    "        alpha = 10 ** (-snr / 20)\n",
    "        y_noisy = y + alpha * noise\n",
    "        y_noisy = y_noisy / np.max(np.abs(y_noisy))\n",
    "\n",
    "        noisy_audio_path = f\"./aist_dataset/audio_snr/temp_audio_{i}_snr{snr}.wav\"\n",
    "        sf.write(noisy_audio_path, y_noisy, sr)\n",
    "\n",
    "        # 2) Beat tracking on NOISY audio ------------------------\n",
    "        proc = DBNBeatTrackingProcessor(fps=100)\n",
    "        act = RNNBeatProcessor()(noisy_audio_path)\n",
    "        beats_audio_noisy = proc(act)\n",
    "\n",
    "        # If beat tracker fails → skip safely\n",
    "        if len(beats_audio_noisy) < 2:\n",
    "            cross_modal_results.append({\n",
    "                \"filename\": vid_nm,\n",
    "                \"snr\": snr,\n",
    "                \"audio_tempo_noisy\": np.nan,\n",
    "                \"corr_max\": np.nan,\n",
    "                \"lag_sec\": np.nan,\n",
    "                \"circ_corr\": np.nan,\n",
    "                \"beat_agreement\": np.nan\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # 3) Compute noisy audio tempo\n",
    "        tempo_audio = 60.0 / np.median(np.diff(beats_audio_noisy))\n",
    "\n",
    "        # 4) Build beat pulse from noisy beats\n",
    "        beat_pulse_audio = np.zeros(int(beats_audio_noisy[-1] * motion_sr) + 1)\n",
    "        beat_frames_audio = (beats_audio_noisy * motion_sr).astype(int)\n",
    "        beat_pulse_audio[beat_frames_audio] = 1\n",
    "\n",
    "        # 5) Motion beat pulse\n",
    "        beat_pulse_motion = hit_beat_pulse[i]\n",
    "\n",
    "        # align lengths\n",
    "        min_len = min(len(beat_pulse_motion), len(beat_pulse_audio))\n",
    "        beat_pulse_motion = beat_pulse_motion[:min_len]\n",
    "        beat_pulse_audio  = beat_pulse_audio[:min_len]\n",
    "\n",
    "        # 6) Linear correlation\n",
    "        corr = correlate(\n",
    "            beat_pulse_motion - np.mean(beat_pulse_motion),\n",
    "            beat_pulse_audio - np.mean(beat_pulse_audio),\n",
    "            mode='full'\n",
    "        )\n",
    "        lag = np.argmax(corr) - (len(beat_pulse_motion) - 1)\n",
    "        max_corr = np.max(corr) / (\n",
    "            np.std(beat_pulse_motion) * np.std(beat_pulse_audio) * len(beat_pulse_motion)\n",
    "        )\n",
    "        lag_sec = lag / motion_sr\n",
    "\n",
    "        # 7) Find motion beat times (using peaks)\n",
    "        peaks_motion, _ = find_peaks(\n",
    "            beat_pulse_motion,\n",
    "            height=np.max(beat_pulse_motion) * 0.5,\n",
    "            distance=motion_sr * 0.3\n",
    "        )\n",
    "        beats_motion = peaks_motion / motion_sr\n",
    "\n",
    "        # 8) Circular correlation --------------------------------\n",
    "        circ_corr = np.nan\n",
    "        if len(beats_motion) > 1:\n",
    "            audio_period = np.median(np.diff(beats_audio_noisy))\n",
    "            motion_phase = 2 * np.pi * ((beats_motion % audio_period) / audio_period)\n",
    "            audio_phase  = 2 * np.pi * ((beats_audio_noisy % audio_period) / audio_period)\n",
    "\n",
    "            n = min(len(motion_phase), len(audio_phase))\n",
    "            motion_phase, audio_phase = motion_phase[:n], audio_phase[:n]\n",
    "\n",
    "            sin_x = np.sin(motion_phase - np.mean(motion_phase))\n",
    "            sin_y = np.sin(audio_phase  - np.mean(audio_phase))\n",
    "            denom = np.sqrt(np.sum(sin_x**2) * np.sum(sin_y**2))\n",
    "\n",
    "            if denom > 0:\n",
    "                circ_corr = np.sum(sin_x * sin_y) / denom\n",
    "\n",
    "        # 9) Beat agreement (±100 ms) -----------------------------\n",
    "        tol = 0.12\n",
    "        beat_agreement = np.mean([\n",
    "            np.any(np.abs(t_a - beats_motion) <= tol)\n",
    "            for t_a in beats_audio_noisy\n",
    "        ])\n",
    "\n",
    "        # 10) Store results ---------------------------------------\n",
    "        cross_modal_results.append({\n",
    "            \"filename\": vid_nm,\n",
    "            \"snr\": snr,\n",
    "            \"audio_tempo_noisy\": tempo_audio,\n",
    "            \"corr_max\": max_corr,\n",
    "            \"lag_sec\": lag_sec,\n",
    "            \"circ_corr\": circ_corr,\n",
    "            \"beat_agreement\": beat_agreement\n",
    "        })\n",
    "\n",
    "    \n",
    "# save dataframe\n",
    "cross_modal_df = pd.DataFrame(cross_modal_results)\n",
    "cross_modal_df.to_csv(\"./cross_modal_alignment_noise.csv\", index=False)\n",
    "\n",
    "df = pd.DataFrame(cross_modal_results)\n",
    "print(df[['corr_max','circ_corr','beat_agreement','lag_sec','audio_tempo']].describe().round(3))\n",
    "\n",
    "# plt.hist(df['corr_max'], bins=20, edgecolor='black')\n",
    "# plt.xlabel('Cross-modal correlation (ρ)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Distribution of Audio–Dance Rhythmic Correlation')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# accuracy_zero['bothhand_y_bothfoot_y_torso_y_uni'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579822b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./cross_modal_alignment_noise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_summary = df.groupby(\"snr\").agg({\n",
    "    \"audio_tempo_noisy\": [\"mean\", \"std\"],\n",
    "    \"corr_max\": [\"mean\", \"std\"],\n",
    "    \"lag_sec\": [\"mean\", \"std\"],\n",
    "    \"circ_corr\": [\"mean\", \"std\"],\n",
    "    \"beat_agreement\": [\"mean\", \"std\"]\n",
    "})\n",
    "\n",
    "print(snr_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
